{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "**Introduction:** \n",
    "The workflow of the autoencoder is as follows,\n",
    "\n",
    "\n",
    "[1] Import the dataset\n",
    "\n",
    "[2] Define the place holders\n",
    "\n",
    "[3] Design the weight vectors(for all the layers of encoder and decoders)\n",
    "\n",
    "[4] Design the biases(for all the layers of encoder and decoders)\n",
    "\n",
    "[5] Build the Encoder section\n",
    "\n",
    "[6] Build the Decoder section\n",
    "\n",
    "[7] Design/ Define the Loss function \n",
    "\n",
    "[8] Design/Define the optimizer \n",
    "\n",
    "[9] Design the training process\n",
    "        (a)Train the network\n",
    "        (b)Test the network (with test sets)\n",
    "        (c)Display the reconstructed image(also the original test image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "**Architechture of the AutoEncoder:**\n",
    "\n",
    "Here we will design a convolutional neural network for the AutoEncoder. The structure of the neural network will be as follows:\n",
    "\n",
    "\n",
    " The Architecture of the AutoEncoder:\n",
    "\n",
    "    · · · · · · · · · ·   -- I (input data, 1-deep) X [batch, 28, 28, 1]\n",
    " \n",
    "    @ @ @ @ @ @ @ @ @ @   -- 1st Encoder conv. layer of: 10x10x1=>10 stride 1,SAME Padding WE1[10, 10, 1, 10],B1[10]\n",
    "                              Note: All Convolution Layers will be activated with Relu\n",
    "    \\/\\/\\/\\/\\/\\/\\/\\/\\/    -- Max pool with kernal[1,2,2,1] and stride [1,2,2,1], SAME Padding                        \n",
    "    ∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶   -- E1 [batch, 14, 14, 10](This is the output of the 1st Encoder convolution layer)\n",
    "    \n",
    "      @ @ @ @ @ @ @ @     -- 2nd Encoder conv. layer of: 5x5x10=>10 stride 1,SAME Padding WE2 [5, 5, 10, 10],B2[10]\n",
    "      \\/\\/\\/\\/\\/\\/\\/      -- Max pool with kernal[1,2,2,1] and stride [1,2,2,1], SAME Padding\n",
    "      ∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶     -- E2 [batch, 7, 7, 10]\n",
    "      \n",
    "       \n",
    "       XXXXXXXXXXX        -- End of Encoder and Start of Decoder, Now for decoding we have to upsample the output\n",
    "                             using: {upsample1 = tf.image.resize_images(E3, size=(14,14), \n",
    "                                                                     method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)}\n",
    "       ^^^^^^^^^^^        -- U1 Upsampling [Batch, 14, 14, 10]                                                              \n",
    "       @ @ @ @ @ @        -- 1st Decoder conv. layer of: 5x5x10=>10 stride 1,SAME Padding WD1[5, 5, 10, 10],C1[10] \n",
    "                             \n",
    "      ∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶     -- D1 [batch, 14, 14, 10] (This is the output of the 1st Decoder convolution layer)\n",
    "      ^^^^^^^^^^^^^^^     -- U2 Upsampling of D1 to size [Batch, 28,28, 10] \n",
    "    \n",
    "    @ @ @ @ @ @ @ @ @     -- 2nd Decoder conv.layer of: 10x10x10=>10 stride1,SAME Padding WD2[10, 10, 10, 10],C2[10]\n",
    "    ∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶:::    -- D2 [batch, 10, 10, 10]\n",
    "    \n",
    "    ...................   -- Logits ConV. Layer of: 10X10X10=>1 stride 1,SAME Padding, WD3 [10, 10,10,1], C3 [1] \n",
    "                            \n",
    "                             Pass the logits through Sigmoid tf.nn.sigmoid(logits)\n",
    "Reference: https://medium.com/towards-data-science/autoencoders-introduction-and-implementation-3f40483b0a85 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division, print_function, absolute_import\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Preaparing Dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "Size of:\n",
      "- Training-set:\t\t55000\n",
      "- Test-set:\t\t10000\n",
      "- Validation-set:\t5000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "data = read_data_sets(\"data\", one_hot=True)\n",
    "\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels))) # here \"\\t\" is for tab\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the Weights:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for declaring weight variable\n",
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "# Here \"tf.truncated_normal\" function returns the graph random values from a truncated normal distribution with a given standard deviation\n",
    "# and \"tf.Variable\" fucntion returns the graph of variables, Here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the Biases:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for declaring Bias variable\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the Encoder:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_encod_layer(input,             # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter(or weights).\n",
    "                   num_filters,        # Number of filters./ or ouput channel\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    # Shape of the filter-weights for the convolution.\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create new weights aka. filters with the given shape.\n",
    "    weights = new_weights(shape=shape)\n",
    "\n",
    "    # Create new biases, one for each filter.\n",
    "    biases = new_biases(length=num_filters)\n",
    "    # The convolutional layer\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "    \n",
    "    # Add the biases to the results of the convolution.\n",
    "    layer += biases\n",
    "\n",
    "    # Use pooling to down-sample the image resolution?\n",
    "    if use_pooling:\n",
    "        # This is 2x2 max-pooling, which means that we\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer, weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the Decoder:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_decod_layer(input,             # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter(or weights)\n",
    "                   num_filters,        # Number of filters./ No of output channel\n",
    "                   upsample_size,      # Upsampling size\n",
    "                   use_upsampling=True):\n",
    "\n",
    "  \n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create new weights aka. filters with the given shape.\n",
    "    weights = new_weights(shape=shape)\n",
    "   \n",
    "    # Create new biases, one for each filter.\n",
    "    biases = new_biases(length=num_filters)\n",
    "   \n",
    "    if use_upsampling:\n",
    "        Upsam=tf.image.resize_images(input, size=(upsample_size,upsample_size), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        \n",
    "        \n",
    "    layer = tf.nn.conv2d(input=Upsam,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "\n",
    "    layer = tf.nn.relu(layer)\n",
    "   \n",
    "    return layer, weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Logits Layer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logits_layer(input,               # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter(or weights).\n",
    "                   num_filters):      # Number of filters./ or ouput channel\n",
    "\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    " \n",
    "    weights = new_weights(shape=shape)\n",
    "\n",
    "  \n",
    "    biases = new_biases(length=num_filters)\n",
    "\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Input and Target Placeholders:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets') # Original image without noise to evaluate the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declaring Encoder layers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Encoder\n",
    "#The input has a dimention of 28x28x1\n",
    "E1, WE1 = new_encod_layer(input=input_image, \n",
    "                         num_input_channels=1,# Because input image is gray\n",
    "                         filter_size=10, # the weight matrix will be of size 10x10\n",
    "                         num_filters=10, # Number of output channel will be 10\n",
    "                         use_pooling=True)\n",
    "#output of the convolutional layer is 14x14x10 since the function max pool and stride at 2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd Encoder\n",
    "#The input has a dimention of 14x14x10\n",
    "E2, WE2 = new_encod_layer(input=E1, \n",
    "                         num_input_channels=10,\n",
    "                         filter_size=5, # the weight matrix will be of size 10x10\n",
    "                         num_filters=10, # No of output channel will be 10\n",
    "                         use_pooling=True)\n",
    "#output of the convolutional layer is of 7x7x10 since the function max pool and stride at 2x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declaring Decoder Layers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Decoder\n",
    "# The input has a dimention of 7X7X10\n",
    "\n",
    "D1, WD1 = new_decod_layer(input=E2,       # The previous layer.\n",
    "                   num_input_channels=10, # Num. channels in prev. layer.\n",
    "                   filter_size=5,         # Width and height of each filter(or weights)\n",
    "                   num_filters=10,        # Number of filters./ No of output channel\n",
    "                   upsample_size=14,      # Upsampling size\n",
    "                   use_upsampling=True) \n",
    "#output of the convolutional layer is of 14x14x10 since the function has 14x14 upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd Decoder\n",
    "# The input has a dimention of 14X14X10\n",
    "\n",
    "D2, WD2 = new_decod_layer(input=D1,       # The previous layer.\n",
    "                   num_input_channels=10, # Num. channels in prev. layer.\n",
    "                   filter_size=10,         # Width and height of each filter(or weights)\n",
    "                   num_filters=10,        # Number of filters./ No of output channel\n",
    "                   upsample_size=28,      # Upsampling size\n",
    "                   use_upsampling=True) \n",
    "#output of the convolutional layer is of 28x28x10 since the function has 14x14 upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declaring Logits Layer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input layer(D2) have a dimention of 28x28x10\n",
    "Logits_Layer_1, Logits_weights = Logits_layer(input=D2,              # The previous layer.\n",
    "                                              num_input_channels=10, # Num. channels in prev.(input) layer.\n",
    "                                              filter_size=10,        # Width and height of each filter(or weights).\n",
    "                                              num_filters=1)       # Number of filters./ or ouput channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reconstruted Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the Loggits through sigmoid to get the reconstructed  image\n",
    "Reconstructed_Image = tf.nn.sigmoid(Logits_Layer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declaring the Loss:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the loss: \n",
    "\n",
    "# Pass logits through sigmoid and calculate the cross-entropy loss\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=Logits_Layer_1)\n",
    "#loss = tf.nn.softmax_cross_entropy_with_logits(labels=targets_, logits=Logits_Layer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimization method:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design of Optimization method\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "#opt = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Training Medthod:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.8298\n",
      "Epoch: 1/1... Training loss: 0.6568\n",
      "Epoch: 1/1... Training loss: 0.5849\n",
      "Epoch: 1/1... Training loss: 0.5411\n",
      "Epoch: 1/1... Training loss: 0.4029\n",
      "Epoch: 1/1... Training loss: 0.6537\n",
      "Epoch: 1/1... Training loss: 0.6194\n",
      "Epoch: 1/1... Training loss: 0.5160\n",
      "Epoch: 1/1... Training loss: 0.5487\n",
      "Epoch: 1/1... Training loss: 0.4897\n",
      "Epoch: 1/1... Training loss: 0.5196\n",
      "Epoch: 1/1... Training loss: 0.4992\n",
      "Epoch: 1/1... Training loss: 0.5162\n",
      "Epoch: 1/1... Training loss: 0.4686\n",
      "Epoch: 1/1... Training loss: 0.5351\n",
      "Epoch: 1/1... Training loss: 0.4441\n",
      "Epoch: 1/1... Training loss: 0.5227\n",
      "Epoch: 1/1... Training loss: 0.4834\n",
      "Epoch: 1/1... Training loss: 0.4449\n",
      "Epoch: 1/1... Training loss: 0.4329\n",
      "Epoch: 1/1... Training loss: 0.4283\n",
      "Epoch: 1/1... Training loss: 0.3802\n",
      "Epoch: 1/1... Training loss: 0.4033\n",
      "Epoch: 1/1... Training loss: 0.4795\n",
      "Epoch: 1/1... Training loss: 0.3646\n",
      "Epoch: 1/1... Training loss: 0.4405\n",
      "Epoch: 1/1... Training loss: 0.3826\n",
      "Epoch: 1/1... Training loss: 0.3763\n",
      "Epoch: 1/1... Training loss: 0.3046\n",
      "Epoch: 1/1... Training loss: 0.3647\n",
      "Epoch: 1/1... Training loss: 0.4401\n",
      "Epoch: 1/1... Training loss: 0.3374\n",
      "Epoch: 1/1... Training loss: 0.3339\n",
      "Epoch: 1/1... Training loss: 0.4429\n",
      "Epoch: 1/1... Training loss: 0.2721\n",
      "Epoch: 1/1... Training loss: 0.3231\n",
      "Epoch: 1/1... Training loss: 0.3009\n",
      "Epoch: 1/1... Training loss: 0.2907\n",
      "Epoch: 1/1... Training loss: 0.2130\n",
      "Epoch: 1/1... Training loss: 0.2831\n",
      "Epoch: 1/1... Training loss: 0.3497\n",
      "Epoch: 1/1... Training loss: 0.2602\n",
      "Epoch: 1/1... Training loss: 0.2975\n",
      "Epoch: 1/1... Training loss: 0.3504\n",
      "Epoch: 1/1... Training loss: 0.2880\n",
      "Epoch: 1/1... Training loss: 0.2504\n",
      "Epoch: 1/1... Training loss: 0.2490\n",
      "Epoch: 1/1... Training loss: 0.2642\n",
      "Epoch: 1/1... Training loss: 0.2724\n",
      "Epoch: 1/1... Training loss: 0.1933\n",
      "Epoch: 1/1... Training loss: 0.1962\n",
      "Epoch: 1/1... Training loss: 0.2621\n",
      "Epoch: 1/1... Training loss: 0.2789\n",
      "Epoch: 1/1... Training loss: 0.2318\n",
      "Epoch: 1/1... Training loss: 0.2580\n",
      "Epoch: 1/1... Training loss: 0.2808\n",
      "Epoch: 1/1... Training loss: 0.3402\n",
      "Epoch: 1/1... Training loss: 0.2217\n",
      "Epoch: 1/1... Training loss: 0.2072\n",
      "Epoch: 1/1... Training loss: 0.2061\n",
      "Epoch: 1/1... Training loss: 0.2548\n",
      "Epoch: 1/1... Training loss: 0.2864\n",
      "Epoch: 1/1... Training loss: 0.2683\n",
      "Epoch: 1/1... Training loss: 0.2501\n",
      "Epoch: 1/1... Training loss: 0.2815\n",
      "Epoch: 1/1... Training loss: 0.2282\n",
      "Epoch: 1/1... Training loss: 0.2756\n",
      "Epoch: 1/1... Training loss: 0.2321\n",
      "Epoch: 1/1... Training loss: 0.2290\n",
      "Epoch: 1/1... Training loss: 0.2498\n",
      "Epoch: 1/1... Training loss: 0.2897\n",
      "Epoch: 1/1... Training loss: 0.2799\n",
      "Epoch: 1/1... Training loss: 0.2383\n",
      "Epoch: 1/1... Training loss: 0.2309\n",
      "Epoch: 1/1... Training loss: 0.2629\n",
      "Epoch: 1/1... Training loss: 0.1994\n",
      "Epoch: 1/1... Training loss: 0.2515\n",
      "Epoch: 1/1... Training loss: 0.2743\n",
      "Epoch: 1/1... Training loss: 0.2872\n",
      "Epoch: 1/1... Training loss: 0.3155\n",
      "Epoch: 1/1... Training loss: 0.2384\n",
      "Epoch: 1/1... Training loss: 0.2380\n",
      "Epoch: 1/1... Training loss: 0.2397\n",
      "Epoch: 1/1... Training loss: 0.2224\n",
      "Epoch: 1/1... Training loss: 0.1931\n",
      "Epoch: 1/1... Training loss: 0.2295\n",
      "Epoch: 1/1... Training loss: 0.1946\n",
      "Epoch: 1/1... Training loss: 0.2230\n",
      "Epoch: 1/1... Training loss: 0.1790\n",
      "Epoch: 1/1... Training loss: 0.2536\n",
      "Epoch: 1/1... Training loss: 0.2251\n",
      "Epoch: 1/1... Training loss: 0.2387\n",
      "Epoch: 1/1... Training loss: 0.2173\n",
      "Epoch: 1/1... Training loss: 0.2012\n",
      "Epoch: 1/1... Training loss: 0.1997\n",
      "Epoch: 1/1... Training loss: 0.1995\n",
      "Epoch: 1/1... Training loss: 0.2275\n",
      "Epoch: 1/1... Training loss: 0.2630\n",
      "Epoch: 1/1... Training loss: 0.2070\n",
      "Epoch: 1/1... Training loss: 0.2683\n",
      "Epoch: 1/1... Training loss: 0.2375\n",
      "Epoch: 1/1... Training loss: 0.2195\n",
      "Epoch: 1/1... Training loss: 0.2046\n",
      "Epoch: 1/1... Training loss: 0.2412\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.2273\n",
      "Epoch: 1/1... Training loss: 0.2664\n",
      "Epoch: 1/1... Training loss: 0.1884\n",
      "Epoch: 1/1... Training loss: 0.2181\n",
      "Epoch: 1/1... Training loss: 0.2462\n",
      "Epoch: 1/1... Training loss: 0.2037\n",
      "Epoch: 1/1... Training loss: 0.2049\n",
      "Epoch: 1/1... Training loss: 0.1886\n",
      "Epoch: 1/1... Training loss: 0.2263\n",
      "Epoch: 1/1... Training loss: 0.1830\n",
      "Epoch: 1/1... Training loss: 0.2657\n",
      "Epoch: 1/1... Training loss: 0.2081\n",
      "Epoch: 1/1... Training loss: 0.2483\n",
      "Epoch: 1/1... Training loss: 0.2043\n",
      "Epoch: 1/1... Training loss: 0.2373\n",
      "Epoch: 1/1... Training loss: 0.1676\n",
      "Epoch: 1/1... Training loss: 0.2106\n",
      "Epoch: 1/1... Training loss: 0.2050\n",
      "Epoch: 1/1... Training loss: 0.1731\n",
      "Epoch: 1/1... Training loss: 0.1741\n",
      "Epoch: 1/1... Training loss: 0.2538\n",
      "Epoch: 1/1... Training loss: 0.2608\n",
      "Epoch: 1/1... Training loss: 0.2434\n",
      "Epoch: 1/1... Training loss: 0.2432\n",
      "Epoch: 1/1... Training loss: 0.2024\n",
      "Epoch: 1/1... Training loss: 0.2387\n",
      "Epoch: 1/1... Training loss: 0.2417\n",
      "Epoch: 1/1... Training loss: 0.2350\n",
      "Epoch: 1/1... Training loss: 0.2422\n",
      "Epoch: 1/1... Training loss: 0.2281\n",
      "Epoch: 1/1... Training loss: 0.2380\n",
      "Epoch: 1/1... Training loss: 0.1913\n",
      "Epoch: 1/1... Training loss: 0.2628\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.2302\n",
      "Epoch: 1/1... Training loss: 0.2295\n",
      "Epoch: 1/1... Training loss: 0.1989\n",
      "Epoch: 1/1... Training loss: 0.2223\n",
      "Epoch: 1/1... Training loss: 0.1821\n",
      "Epoch: 1/1... Training loss: 0.2030\n",
      "Epoch: 1/1... Training loss: 0.1910\n",
      "Epoch: 1/1... Training loss: 0.1944\n",
      "Epoch: 1/1... Training loss: 0.2943\n",
      "Epoch: 1/1... Training loss: 0.2341\n",
      "Epoch: 1/1... Training loss: 0.2203\n",
      "Epoch: 1/1... Training loss: 0.1992\n",
      "Epoch: 1/1... Training loss: 0.2103\n",
      "Epoch: 1/1... Training loss: 0.2321\n",
      "Epoch: 1/1... Training loss: 0.1729\n",
      "Epoch: 1/1... Training loss: 0.2051\n",
      "Epoch: 1/1... Training loss: 0.1952\n",
      "Epoch: 1/1... Training loss: 0.2247\n",
      "Epoch: 1/1... Training loss: 0.2755\n",
      "Epoch: 1/1... Training loss: 0.1706\n",
      "Epoch: 1/1... Training loss: 0.1874\n",
      "Epoch: 1/1... Training loss: 0.1932\n",
      "Epoch: 1/1... Training loss: 0.2530\n",
      "Epoch: 1/1... Training loss: 0.2040\n",
      "Epoch: 1/1... Training loss: 0.2050\n",
      "Epoch: 1/1... Training loss: 0.2043\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1844\n",
      "Epoch: 1/1... Training loss: 0.2724\n",
      "Epoch: 1/1... Training loss: 0.2225\n",
      "Epoch: 1/1... Training loss: 0.1764\n",
      "Epoch: 1/1... Training loss: 0.1615\n",
      "Epoch: 1/1... Training loss: 0.1829\n",
      "Epoch: 1/1... Training loss: 0.1902\n",
      "Epoch: 1/1... Training loss: 0.1700\n",
      "Epoch: 1/1... Training loss: 0.1900\n",
      "Epoch: 1/1... Training loss: 0.2503\n",
      "Epoch: 1/1... Training loss: 0.2161\n",
      "Epoch: 1/1... Training loss: 0.1806\n",
      "Epoch: 1/1... Training loss: 0.1842\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.2011\n",
      "Epoch: 1/1... Training loss: 0.2374\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.2021\n",
      "Epoch: 1/1... Training loss: 0.2214\n",
      "Epoch: 1/1... Training loss: 0.1854\n",
      "Epoch: 1/1... Training loss: 0.2292\n",
      "Epoch: 1/1... Training loss: 0.2085\n",
      "Epoch: 1/1... Training loss: 0.2096\n",
      "Epoch: 1/1... Training loss: 0.1744\n",
      "Epoch: 1/1... Training loss: 0.1728\n",
      "Epoch: 1/1... Training loss: 0.1966\n",
      "Epoch: 1/1... Training loss: 0.1863\n",
      "Epoch: 1/1... Training loss: 0.2335\n",
      "Epoch: 1/1... Training loss: 0.1905\n",
      "Epoch: 1/1... Training loss: 0.2336\n",
      "Epoch: 1/1... Training loss: 0.2076\n",
      "Epoch: 1/1... Training loss: 0.1669\n",
      "Epoch: 1/1... Training loss: 0.1935\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1866\n",
      "Epoch: 1/1... Training loss: 0.1897\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.2732\n",
      "Epoch: 1/1... Training loss: 0.1946\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.2035\n",
      "Epoch: 1/1... Training loss: 0.2190\n",
      "Epoch: 1/1... Training loss: 0.1845\n",
      "Epoch: 1/1... Training loss: 0.2321\n",
      "Epoch: 1/1... Training loss: 0.2116\n",
      "Epoch: 1/1... Training loss: 0.2040\n",
      "Epoch: 1/1... Training loss: 0.2079\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.2034\n",
      "Epoch: 1/1... Training loss: 0.1853\n",
      "Epoch: 1/1... Training loss: 0.2043\n",
      "Epoch: 1/1... Training loss: 0.2201\n",
      "Epoch: 1/1... Training loss: 0.2313\n",
      "Epoch: 1/1... Training loss: 0.1928\n",
      "Epoch: 1/1... Training loss: 0.1978\n",
      "Epoch: 1/1... Training loss: 0.1879\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1980\n",
      "Epoch: 1/1... Training loss: 0.2129\n",
      "Epoch: 1/1... Training loss: 0.2024\n",
      "Epoch: 1/1... Training loss: 0.1976\n",
      "Epoch: 1/1... Training loss: 0.1931\n",
      "Epoch: 1/1... Training loss: 0.1933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1904\n",
      "Epoch: 1/1... Training loss: 0.2200\n",
      "Epoch: 1/1... Training loss: 0.1663\n",
      "Epoch: 1/1... Training loss: 0.2236\n",
      "Epoch: 1/1... Training loss: 0.1963\n",
      "Epoch: 1/1... Training loss: 0.1959\n",
      "Epoch: 1/1... Training loss: 0.1757\n",
      "Epoch: 1/1... Training loss: 0.1816\n",
      "Epoch: 1/1... Training loss: 0.1801\n",
      "Epoch: 1/1... Training loss: 0.1811\n",
      "Epoch: 1/1... Training loss: 0.1811\n",
      "Epoch: 1/1... Training loss: 0.2041\n",
      "Epoch: 1/1... Training loss: 0.1690\n",
      "Epoch: 1/1... Training loss: 0.2407\n",
      "Epoch: 1/1... Training loss: 0.2030\n",
      "Epoch: 1/1... Training loss: 0.1573\n",
      "Epoch: 1/1... Training loss: 0.2248\n",
      "Epoch: 1/1... Training loss: 0.2023\n",
      "Epoch: 1/1... Training loss: 0.2150\n",
      "Epoch: 1/1... Training loss: 0.1864\n",
      "Epoch: 1/1... Training loss: 0.1757\n",
      "Epoch: 1/1... Training loss: 0.1917\n",
      "Epoch: 1/1... Training loss: 0.1710\n",
      "Epoch: 1/1... Training loss: 0.1813\n",
      "Epoch: 1/1... Training loss: 0.2294\n",
      "Epoch: 1/1... Training loss: 0.1862\n",
      "Epoch: 1/1... Training loss: 0.1872\n",
      "Epoch: 1/1... Training loss: 0.1879\n",
      "Epoch: 1/1... Training loss: 0.2100\n",
      "Epoch: 1/1... Training loss: 0.1939\n",
      "Epoch: 1/1... Training loss: 0.1810\n",
      "Epoch: 1/1... Training loss: 0.1838\n",
      "Epoch: 1/1... Training loss: 0.2062\n",
      "Epoch: 1/1... Training loss: 0.1998\n",
      "Epoch: 1/1... Training loss: 0.1834\n",
      "Epoch: 1/1... Training loss: 0.1921\n",
      "Epoch: 1/1... Training loss: 0.1760\n",
      "Epoch: 1/1... Training loss: 0.2026\n",
      "Epoch: 1/1... Training loss: 0.1694\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1879\n",
      "Epoch: 1/1... Training loss: 0.2235\n",
      "Epoch: 1/1... Training loss: 0.1960\n",
      "Epoch: 1/1... Training loss: 0.1680\n",
      "Epoch: 1/1... Training loss: 0.1867\n",
      "Epoch: 1/1... Training loss: 0.1895\n",
      "Epoch: 1/1... Training loss: 0.2085\n",
      "Epoch: 1/1... Training loss: 0.2244\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1896\n",
      "Epoch: 1/1... Training loss: 0.1782\n",
      "Epoch: 1/1... Training loss: 0.1753\n",
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1847\n",
      "Epoch: 1/1... Training loss: 0.2019\n",
      "Epoch: 1/1... Training loss: 0.2693\n",
      "Epoch: 1/1... Training loss: 0.1805\n",
      "Epoch: 1/1... Training loss: 0.1854\n",
      "Epoch: 1/1... Training loss: 0.1899\n",
      "Epoch: 1/1... Training loss: 0.1733\n",
      "Epoch: 1/1... Training loss: 0.1913\n",
      "Epoch: 1/1... Training loss: 0.2166\n",
      "Epoch: 1/1... Training loss: 0.1732\n",
      "Epoch: 1/1... Training loss: 0.1816\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.2100\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.2140\n",
      "Epoch: 1/1... Training loss: 0.1909\n",
      "Epoch: 1/1... Training loss: 0.1825\n",
      "Epoch: 1/1... Training loss: 0.2233\n",
      "Epoch: 1/1... Training loss: 0.1973\n",
      "Epoch: 1/1... Training loss: 0.2194\n",
      "Epoch: 1/1... Training loss: 0.2364\n",
      "Epoch: 1/1... Training loss: 0.1746\n",
      "Epoch: 1/1... Training loss: 0.2052\n",
      "Epoch: 1/1... Training loss: 0.1845\n",
      "Epoch: 1/1... Training loss: 0.1781\n",
      "Epoch: 1/1... Training loss: 0.1895\n",
      "Epoch: 1/1... Training loss: 0.1647\n",
      "Epoch: 1/1... Training loss: 0.2214\n",
      "Epoch: 1/1... Training loss: 0.1841\n",
      "Epoch: 1/1... Training loss: 0.2575\n",
      "Epoch: 1/1... Training loss: 0.2251\n",
      "Epoch: 1/1... Training loss: 0.2005\n",
      "Epoch: 1/1... Training loss: 0.1932\n",
      "Epoch: 1/1... Training loss: 0.2214\n",
      "Epoch: 1/1... Training loss: 0.2125\n",
      "Epoch: 1/1... Training loss: 0.2231\n",
      "Epoch: 1/1... Training loss: 0.2019\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.2195\n",
      "Epoch: 1/1... Training loss: 0.2430\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.2544\n",
      "Epoch: 1/1... Training loss: 0.1816\n",
      "Epoch: 1/1... Training loss: 0.1955\n",
      "Epoch: 1/1... Training loss: 0.2138\n",
      "Epoch: 1/1... Training loss: 0.1825\n",
      "Epoch: 1/1... Training loss: 0.1745\n",
      "Epoch: 1/1... Training loss: 0.1734\n",
      "Epoch: 1/1... Training loss: 0.2027\n",
      "Epoch: 1/1... Training loss: 0.1817\n",
      "Epoch: 1/1... Training loss: 0.1972\n",
      "Epoch: 1/1... Training loss: 0.1828\n",
      "Epoch: 1/1... Training loss: 0.1855\n",
      "Epoch: 1/1... Training loss: 0.2110\n",
      "Epoch: 1/1... Training loss: 0.1607\n",
      "Epoch: 1/1... Training loss: 0.1731\n",
      "Epoch: 1/1... Training loss: 0.2024\n",
      "Epoch: 1/1... Training loss: 0.1604\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1795\n",
      "Epoch: 1/1... Training loss: 0.1950\n",
      "Epoch: 1/1... Training loss: 0.2448\n",
      "Epoch: 1/1... Training loss: 0.2213\n",
      "Epoch: 1/1... Training loss: 0.1969\n",
      "Epoch: 1/1... Training loss: 0.1832\n",
      "Epoch: 1/1... Training loss: 0.2316\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1986\n",
      "Epoch: 1/1... Training loss: 0.1794\n",
      "Epoch: 1/1... Training loss: 0.1835\n",
      "Epoch: 1/1... Training loss: 0.2332\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.2002\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1959\n",
      "Epoch: 1/1... Training loss: 0.1940\n",
      "Epoch: 1/1... Training loss: 0.1823\n",
      "Epoch: 1/1... Training loss: 0.1714\n",
      "Epoch: 1/1... Training loss: 0.1669\n",
      "Epoch: 1/1... Training loss: 0.2403\n",
      "Epoch: 1/1... Training loss: 0.1754\n",
      "Epoch: 1/1... Training loss: 0.1987\n",
      "Epoch: 1/1... Training loss: 0.1573\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.2237\n",
      "Epoch: 1/1... Training loss: 0.2172\n",
      "Epoch: 1/1... Training loss: 0.1768\n",
      "Epoch: 1/1... Training loss: 0.2096\n",
      "Epoch: 1/1... Training loss: 0.1858\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1773\n",
      "Epoch: 1/1... Training loss: 0.1822\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1848\n",
      "Epoch: 1/1... Training loss: 0.1869\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1967\n",
      "Epoch: 1/1... Training loss: 0.1743\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1895\n",
      "Epoch: 1/1... Training loss: 0.1835\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1915\n",
      "Epoch: 1/1... Training loss: 0.1764\n",
      "Epoch: 1/1... Training loss: 0.1755\n",
      "Epoch: 1/1... Training loss: 0.1609\n",
      "Epoch: 1/1... Training loss: 0.1729\n",
      "Epoch: 1/1... Training loss: 0.1981\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1777\n",
      "Epoch: 1/1... Training loss: 0.1873\n",
      "Epoch: 1/1... Training loss: 0.1724\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.2170\n",
      "Epoch: 1/1... Training loss: 0.1653\n",
      "Epoch: 1/1... Training loss: 0.1553\n",
      "Epoch: 1/1... Training loss: 0.1852\n",
      "Epoch: 1/1... Training loss: 0.1709\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1969\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.2026\n",
      "Epoch: 1/1... Training loss: 0.2160\n",
      "Epoch: 1/1... Training loss: 0.1770\n",
      "Epoch: 1/1... Training loss: 0.2003\n",
      "Epoch: 1/1... Training loss: 0.1700\n",
      "Epoch: 1/1... Training loss: 0.1992\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1768\n",
      "Epoch: 1/1... Training loss: 0.1913\n",
      "Epoch: 1/1... Training loss: 0.1712\n",
      "Epoch: 1/1... Training loss: 0.1647\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1917\n",
      "Epoch: 1/1... Training loss: 0.2094\n",
      "Epoch: 1/1... Training loss: 0.2182\n",
      "Epoch: 1/1... Training loss: 0.1601\n",
      "Epoch: 1/1... Training loss: 0.1911\n",
      "Epoch: 1/1... Training loss: 0.1664\n",
      "Epoch: 1/1... Training loss: 0.1708\n",
      "Epoch: 1/1... Training loss: 0.2216\n",
      "Epoch: 1/1... Training loss: 0.1685\n",
      "Epoch: 1/1... Training loss: 0.1912\n",
      "Epoch: 1/1... Training loss: 0.1616\n",
      "Epoch: 1/1... Training loss: 0.1785\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1902\n",
      "Epoch: 1/1... Training loss: 0.1814\n",
      "Epoch: 1/1... Training loss: 0.1918\n",
      "Epoch: 1/1... Training loss: 0.1968\n",
      "Epoch: 1/1... Training loss: 0.1956\n",
      "Epoch: 1/1... Training loss: 0.1825\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.2064\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.2095\n",
      "Epoch: 1/1... Training loss: 0.1903\n",
      "Epoch: 1/1... Training loss: 0.1922\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.2058\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1963\n",
      "Epoch: 1/1... Training loss: 0.1656\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1863\n",
      "Epoch: 1/1... Training loss: 0.1905\n",
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1684\n",
      "Epoch: 1/1... Training loss: 0.1629\n",
      "Epoch: 1/1... Training loss: 0.2175\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1877\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1660\n",
      "Epoch: 1/1... Training loss: 0.2300\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1651\n",
      "Epoch: 1/1... Training loss: 0.1808\n",
      "Epoch: 1/1... Training loss: 0.1934\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1817\n",
      "Epoch: 1/1... Training loss: 0.1810\n",
      "Epoch: 1/1... Training loss: 0.1860\n",
      "Epoch: 1/1... Training loss: 0.1946\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1936\n",
      "Epoch: 1/1... Training loss: 0.1713\n",
      "Epoch: 1/1... Training loss: 0.1884\n",
      "Epoch: 1/1... Training loss: 0.2027\n",
      "Epoch: 1/1... Training loss: 0.1832\n",
      "Epoch: 1/1... Training loss: 0.1989\n",
      "Epoch: 1/1... Training loss: 0.1651\n",
      "Epoch: 1/1... Training loss: 0.1930\n",
      "Epoch: 1/1... Training loss: 0.1809\n",
      "Epoch: 1/1... Training loss: 0.1647\n",
      "Epoch: 1/1... Training loss: 0.1722\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.2031\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1783\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1678\n",
      "Epoch: 1/1... Training loss: 0.1890\n",
      "Epoch: 1/1... Training loss: 0.1721\n",
      "Epoch: 1/1... Training loss: 0.2087\n",
      "Epoch: 1/1... Training loss: 0.1859\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1807\n",
      "Epoch: 1/1... Training loss: 0.1760\n",
      "Epoch: 1/1... Training loss: 0.2069\n",
      "Epoch: 1/1... Training loss: 0.1935\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1687\n",
      "Epoch: 1/1... Training loss: 0.1777\n",
      "Epoch: 1/1... Training loss: 0.1940\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1958\n",
      "Epoch: 1/1... Training loss: 0.1935\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.2278\n",
      "Epoch: 1/1... Training loss: 0.1774\n",
      "Epoch: 1/1... Training loss: 0.1923\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.2241\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1863\n",
      "Epoch: 1/1... Training loss: 0.1760\n",
      "Epoch: 1/1... Training loss: 0.1903\n",
      "Epoch: 1/1... Training loss: 0.1971\n",
      "Epoch: 1/1... Training loss: 0.1855\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1876\n",
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1759\n",
      "Epoch: 1/1... Training loss: 0.2047\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1553\n",
      "Epoch: 1/1... Training loss: 0.1579\n",
      "Epoch: 1/1... Training loss: 0.1587\n",
      "Epoch: 1/1... Training loss: 0.1623\n",
      "Epoch: 1/1... Training loss: 0.0959\n",
      "Epoch: 1/1... Training loss: 0.1691\n",
      "Epoch: 1/1... Training loss: 0.2259\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1870\n",
      "Epoch: 1/1... Training loss: 0.1711\n",
      "Epoch: 1/1... Training loss: 0.1757\n",
      "Epoch: 1/1... Training loss: 0.1662\n",
      "Epoch: 1/1... Training loss: 0.1854\n",
      "Epoch: 1/1... Training loss: 0.2042\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1811\n",
      "Epoch: 1/1... Training loss: 0.1860\n",
      "Epoch: 1/1... Training loss: 0.2080\n",
      "Epoch: 1/1... Training loss: 0.1767\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.2018\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1627\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1563\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.2016\n",
      "Epoch: 1/1... Training loss: 0.1994\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1804\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1657\n",
      "Epoch: 1/1... Training loss: 0.1976\n",
      "Epoch: 1/1... Training loss: 0.1635\n",
      "Epoch: 1/1... Training loss: 0.1888\n",
      "Epoch: 1/1... Training loss: 0.1790\n",
      "Epoch: 1/1... Training loss: 0.1834\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1682\n",
      "Epoch: 1/1... Training loss: 0.1793\n",
      "Epoch: 1/1... Training loss: 0.1714\n",
      "Epoch: 1/1... Training loss: 0.1726\n",
      "Epoch: 1/1... Training loss: 0.2088\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1660\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1885\n",
      "Epoch: 1/1... Training loss: 0.1752\n",
      "Epoch: 1/1... Training loss: 0.2061\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1840\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1739\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.0985\n",
      "Epoch: 1/1... Training loss: 0.1674\n",
      "Epoch: 1/1... Training loss: 0.1647\n",
      "Epoch: 1/1... Training loss: 0.1920\n",
      "Epoch: 1/1... Training loss: 0.2120\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1053\n",
      "Epoch: 1/1... Training loss: 0.1794\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1697\n",
      "Epoch: 1/1... Training loss: 0.1860\n",
      "Epoch: 1/1... Training loss: 0.1697\n",
      "Epoch: 1/1... Training loss: 0.1729\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1761\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.0942\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1699\n",
      "Epoch: 1/1... Training loss: 0.1859\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1858\n",
      "Epoch: 1/1... Training loss: 0.1838\n",
      "Epoch: 1/1... Training loss: 0.1889\n",
      "Epoch: 1/1... Training loss: 0.2098\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1938\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1727\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1904\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1616\n",
      "Epoch: 1/1... Training loss: 0.1990\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1993\n",
      "Epoch: 1/1... Training loss: 0.2187\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1923\n",
      "Epoch: 1/1... Training loss: 0.1997\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1714\n",
      "Epoch: 1/1... Training loss: 0.1659\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1680\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.2204\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1731\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1620\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1800\n",
      "Epoch: 1/1... Training loss: 0.1731\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.2012\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1746\n",
      "Epoch: 1/1... Training loss: 0.2032\n",
      "Epoch: 1/1... Training loss: 0.2257\n",
      "Epoch: 1/1... Training loss: 0.1815\n",
      "Epoch: 1/1... Training loss: 0.1809\n",
      "Epoch: 1/1... Training loss: 0.1590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1760\n",
      "Epoch: 1/1... Training loss: 0.1633\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.2072\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1755\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.2308\n",
      "Epoch: 1/1... Training loss: 0.1642\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1786\n",
      "Epoch: 1/1... Training loss: 0.1726\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1873\n",
      "Epoch: 1/1... Training loss: 0.1839\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1870\n",
      "Epoch: 1/1... Training loss: 0.1702\n",
      "Epoch: 1/1... Training loss: 0.1727\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1021\n",
      "Epoch: 1/1... Training loss: 0.2051\n",
      "Epoch: 1/1... Training loss: 0.1724\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1678\n",
      "Epoch: 1/1... Training loss: 0.1872\n",
      "Epoch: 1/1... Training loss: 0.1641\n",
      "Epoch: 1/1... Training loss: 0.2107\n",
      "Epoch: 1/1... Training loss: 0.1669\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1960\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1911\n",
      "Epoch: 1/1... Training loss: 0.1878\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1885\n",
      "Epoch: 1/1... Training loss: 0.1820\n",
      "Epoch: 1/1... Training loss: 0.2014\n",
      "Epoch: 1/1... Training loss: 0.1897\n",
      "Epoch: 1/1... Training loss: 0.1717\n",
      "Epoch: 1/1... Training loss: 0.1833\n",
      "Epoch: 1/1... Training loss: 0.1611\n",
      "Epoch: 1/1... Training loss: 0.2022\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.2132\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1873\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1858\n",
      "Epoch: 1/1... Training loss: 0.1928\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1728\n",
      "Epoch: 1/1... Training loss: 0.1854\n",
      "Epoch: 1/1... Training loss: 0.1627\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.0975\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1753\n",
      "Epoch: 1/1... Training loss: 0.1779\n",
      "Epoch: 1/1... Training loss: 0.1744\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1836\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1756\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1686\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1843\n",
      "Epoch: 1/1... Training loss: 0.1616\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1706\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1867\n",
      "Epoch: 1/1... Training loss: 0.1623\n",
      "Epoch: 1/1... Training loss: 0.1745\n",
      "Epoch: 1/1... Training loss: 0.1672\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.2168\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1864\n",
      "Epoch: 1/1... Training loss: 0.1868\n",
      "Epoch: 1/1... Training loss: 0.1809\n",
      "Epoch: 1/1... Training loss: 0.1756\n",
      "Epoch: 1/1... Training loss: 0.1788\n",
      "Epoch: 1/1... Training loss: 0.1743\n",
      "Epoch: 1/1... Training loss: 0.1561\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1915\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1908\n",
      "Epoch: 1/1... Training loss: 0.2054\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1840\n",
      "Epoch: 1/1... Training loss: 0.1913\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1647\n",
      "Epoch: 1/1... Training loss: 0.1740\n",
      "Epoch: 1/1... Training loss: 0.1784\n",
      "Epoch: 1/1... Training loss: 0.1616\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.2147\n",
      "Epoch: 1/1... Training loss: 0.1652\n",
      "Epoch: 1/1... Training loss: 0.1836\n",
      "Epoch: 1/1... Training loss: 0.1553\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1831\n",
      "Epoch: 1/1... Training loss: 0.1832\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1692\n",
      "Epoch: 1/1... Training loss: 0.1838\n",
      "Epoch: 1/1... Training loss: 0.1695\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.2081\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1979\n",
      "Epoch: 1/1... Training loss: 0.1980\n",
      "Epoch: 1/1... Training loss: 0.1843\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1904\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1713\n",
      "Epoch: 1/1... Training loss: 0.1609\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1757\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1678\n",
      "Epoch: 1/1... Training loss: 0.2032\n",
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1682\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.0931\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1744\n",
      "Epoch: 1/1... Training loss: 0.1625\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1946\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1940\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1792\n",
      "Epoch: 1/1... Training loss: 0.1894\n",
      "Epoch: 1/1... Training loss: 0.1676\n",
      "Epoch: 1/1... Training loss: 0.1875\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1677\n",
      "Epoch: 1/1... Training loss: 0.1796\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1850\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1786\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1086\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1774\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1985\n",
      "Epoch: 1/1... Training loss: 0.1819\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1864\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1900\n",
      "Epoch: 1/1... Training loss: 0.1011\n",
      "Epoch: 1/1... Training loss: 0.1785\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1743\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.2018\n",
      "Epoch: 1/1... Training loss: 0.1776\n",
      "Epoch: 1/1... Training loss: 0.1752\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.2038\n",
      "Epoch: 1/1... Training loss: 0.1732\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1839\n",
      "Epoch: 1/1... Training loss: 0.1406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1611\n",
      "Epoch: 1/1... Training loss: 0.2200\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1603\n",
      "Epoch: 1/1... Training loss: 0.1702\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1519\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.2300\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1815\n",
      "Epoch: 1/1... Training loss: 0.1719\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1051\n",
      "Epoch: 1/1... Training loss: 0.1625\n",
      "Epoch: 1/1... Training loss: 0.1681\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1804\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1669\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1697\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1752\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1945\n",
      "Epoch: 1/1... Training loss: 0.1625\n",
      "Epoch: 1/1... Training loss: 0.1680\n",
      "Epoch: 1/1... Training loss: 0.1770\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.2176\n",
      "Epoch: 1/1... Training loss: 0.1740\n",
      "Epoch: 1/1... Training loss: 0.1979\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1825\n",
      "Epoch: 1/1... Training loss: 0.1815\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1730\n",
      "Epoch: 1/1... Training loss: 0.1829\n",
      "Epoch: 1/1... Training loss: 0.2006\n",
      "Epoch: 1/1... Training loss: 0.1854\n",
      "Epoch: 1/1... Training loss: 0.2012\n",
      "Epoch: 1/1... Training loss: 0.1997\n",
      "Epoch: 1/1... Training loss: 0.1832\n",
      "Epoch: 1/1... Training loss: 0.1714\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1516\n",
      "Epoch: 1/1... Training loss: 0.1877\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1774\n",
      "Epoch: 1/1... Training loss: 0.1788\n",
      "Epoch: 1/1... Training loss: 0.2113\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1786\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1706\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1847\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1650\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1655\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1561\n",
      "Epoch: 1/1... Training loss: 0.1669\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1634\n",
      "Epoch: 1/1... Training loss: 0.1761\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1919\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1746\n",
      "Epoch: 1/1... Training loss: 0.1673\n",
      "Epoch: 1/1... Training loss: 0.1639\n",
      "Epoch: 1/1... Training loss: 0.1610\n",
      "Epoch: 1/1... Training loss: 0.1633\n",
      "Epoch: 1/1... Training loss: 0.1933\n",
      "Epoch: 1/1... Training loss: 0.1582\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1677\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1827\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1907\n",
      "Epoch: 1/1... Training loss: 0.1851\n",
      "Epoch: 1/1... Training loss: 0.1741\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1625\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1024\n",
      "Epoch: 1/1... Training loss: 0.1602\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1764\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1728\n",
      "Epoch: 1/1... Training loss: 0.1781\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1020\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1599\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1962\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1652\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1846\n",
      "Epoch: 1/1... Training loss: 0.1669\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1783\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.2313\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1774\n",
      "Epoch: 1/1... Training loss: 0.1705\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1650\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1855\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1712\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1748\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1772\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1603\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1909\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1660\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1842\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1886\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1620\n",
      "Epoch: 1/1... Training loss: 0.1816\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1646\n",
      "Epoch: 1/1... Training loss: 0.0995\n",
      "Epoch: 1/1... Training loss: 0.1789\n",
      "Epoch: 1/1... Training loss: 0.1691\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1660\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1798\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1733\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.2450\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1725\n",
      "Epoch: 1/1... Training loss: 0.1695\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.2060\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1633\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1879\n",
      "Epoch: 1/1... Training loss: 0.1734\n",
      "Epoch: 1/1... Training loss: 0.1895\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1708\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.0984\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1587\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1705\n",
      "Epoch: 1/1... Training loss: 0.1726\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1746\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1801\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1697\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1096\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1728\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1835\n",
      "Epoch: 1/1... Training loss: 0.1627\n",
      "Epoch: 1/1... Training loss: 0.1721\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1060\n",
      "Epoch: 1/1... Training loss: 0.1844\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1829\n",
      "Epoch: 1/1... Training loss: 0.1804\n",
      "Epoch: 1/1... Training loss: 0.1695\n",
      "Epoch: 1/1... Training loss: 0.1825\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1701\n",
      "Epoch: 1/1... Training loss: 0.1746\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1746\n",
      "Epoch: 1/1... Training loss: 0.1799\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1755\n",
      "Epoch: 1/1... Training loss: 0.2265\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1561\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1634\n",
      "Epoch: 1/1... Training loss: 0.0979\n",
      "Epoch: 1/1... Training loss: 0.1642\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1729\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1902\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1705\n",
      "Epoch: 1/1... Training loss: 0.1696\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1745\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1757\n",
      "Epoch: 1/1... Training loss: 0.1604\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1673\n",
      "Epoch: 1/1... Training loss: 0.1846\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1730\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1645\n",
      "Epoch: 1/1... Training loss: 0.1789\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1769\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.1643\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1692\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1863\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1782\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1877\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.0923\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1729\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1805\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1660\n",
      "Epoch: 1/1... Training loss: 0.1823\n",
      "Epoch: 1/1... Training loss: 0.0963\n",
      "Epoch: 1/1... Training loss: 0.1573\n",
      "Epoch: 1/1... Training loss: 0.1723\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1705\n",
      "Epoch: 1/1... Training loss: 0.1769\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1597\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1968\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1666\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1609\n",
      "Epoch: 1/1... Training loss: 0.1620\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1599\n",
      "Epoch: 1/1... Training loss: 0.1727\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1756\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1768\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1822\n",
      "Epoch: 1/1... Training loss: 0.1684\n",
      "Epoch: 1/1... Training loss: 0.1726\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1850\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.2104\n",
      "Epoch: 1/1... Training loss: 0.1814\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.1846\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1732\n",
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1644\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1687\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1790\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1633\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1747\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1724\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1881\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1782\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1653\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1732\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1797\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.2604\n",
      "Epoch: 1/1... Training loss: 0.1752\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1746\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1861\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1869\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1768\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1645\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1754\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1047\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1819\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.0961\n",
      "Epoch: 1/1... Training loss: 0.1781\n",
      "Epoch: 1/1... Training loss: 0.1773\n",
      "Epoch: 1/1... Training loss: 0.1792\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1871\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1629\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1603\n",
      "Epoch: 1/1... Training loss: 0.1655\n",
      "Epoch: 1/1... Training loss: 0.1858\n",
      "Epoch: 1/1... Training loss: 0.1629\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1830\n",
      "Epoch: 1/1... Training loss: 0.1643\n",
      "Epoch: 1/1... Training loss: 0.1153\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1662\n",
      "Epoch: 1/1... Training loss: 0.1911\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.2013\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1666\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1717\n",
      "Epoch: 1/1... Training loss: 0.1663\n",
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1582\n",
      "Epoch: 1/1... Training loss: 0.1690\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1652\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.0944\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1770\n",
      "Epoch: 1/1... Training loss: 0.1698\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1823\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1950\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1739\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1736\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1730\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1573\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1685\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1733\n",
      "Epoch: 1/1... Training loss: 0.1629\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1662\n",
      "Epoch: 1/1... Training loss: 0.1812\n",
      "Epoch: 1/1... Training loss: 0.1857\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1876\n",
      "Epoch: 1/1... Training loss: 0.1772\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1884\n",
      "Epoch: 1/1... Training loss: 0.1013\n",
      "Epoch: 1/1... Training loss: 0.1654\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1709\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1607\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.0985\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1623\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1611\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1823\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.2033\n",
      "Epoch: 1/1... Training loss: 0.1684\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1621\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1696\n",
      "Epoch: 1/1... Training loss: 0.1745\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1626\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1913\n",
      "Epoch: 1/1... Training loss: 0.1753\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1694\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1844\n",
      "Epoch: 1/1... Training loss: 0.0981\n",
      "Epoch: 1/1... Training loss: 0.1650\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.1107\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1743\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1053\n",
      "Epoch: 1/1... Training loss: 0.1627\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1609\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1001\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.2003\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1626\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1553\n",
      "Epoch: 1/1... Training loss: 0.1916\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1117\n",
      "Epoch: 1/1... Training loss: 0.1709\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1021\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1679\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1718\n",
      "Epoch: 1/1... Training loss: 0.1916\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.0978\n",
      "Epoch: 1/1... Training loss: 0.1607\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1913\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1082\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1709\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1754\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1697\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.0973\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1788\n",
      "Epoch: 1/1... Training loss: 0.1629\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1695\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1048\n",
      "Epoch: 1/1... Training loss: 0.1718\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1838\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1728\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1817\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.1650\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1873\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.0896\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1591\n",
      "Epoch: 1/1... Training loss: 0.1597\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1686\n",
      "Epoch: 1/1... Training loss: 0.0810\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1627\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1801\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1710\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.0897\n",
      "Epoch: 1/1... Training loss: 0.0955\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1107\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1089\n",
      "Epoch: 1/1... Training loss: 0.1650\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1051\n",
      "Epoch: 1/1... Training loss: 0.1655\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1693\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1621\n",
      "Epoch: 1/1... Training loss: 0.1756\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1699\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1783\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1652\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1872\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1967\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1735\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.0978\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1751\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1035\n",
      "Epoch: 1/1... Training loss: 0.1848\n",
      "Epoch: 1/1... Training loss: 0.1045\n",
      "Epoch: 1/1... Training loss: 0.1797\n",
      "Epoch: 1/1... Training loss: 0.1652\n",
      "Epoch: 1/1... Training loss: 0.1073\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1766\n",
      "Epoch: 1/1... Training loss: 0.1681\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.2050\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1044\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1690\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1706\n",
      "Epoch: 1/1... Training loss: 0.1745\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1716\n",
      "Epoch: 1/1... Training loss: 0.1033\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1852\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1563\n",
      "Epoch: 1/1... Training loss: 0.1601\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1569\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1048\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1645\n",
      "Epoch: 1/1... Training loss: 0.1816\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1770\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1704\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1603\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1797\n",
      "Epoch: 1/1... Training loss: 0.1597\n",
      "Epoch: 1/1... Training loss: 0.2048\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1732\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1153\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1634\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1698\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1516\n",
      "Epoch: 1/1... Training loss: 0.1803\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1620\n",
      "Epoch: 1/1... Training loss: 0.1671\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1999\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1018\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1651\n",
      "Epoch: 1/1... Training loss: 0.1751\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1875\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1870\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1553\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1607\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1634\n",
      "Epoch: 1/1... Training loss: 0.1671\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1686\n",
      "Epoch: 1/1... Training loss: 0.1591\n",
      "Epoch: 1/1... Training loss: 0.1007\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1644\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1582\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1781\n",
      "Epoch: 1/1... Training loss: 0.1623\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1616\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1884\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1925\n",
      "Epoch: 1/1... Training loss: 0.1076\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.0929\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.1260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1903\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1620\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1880\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1021\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.0965\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1760\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1553\n",
      "Epoch: 1/1... Training loss: 0.1974\n",
      "Epoch: 1/1... Training loss: 0.1724\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1642\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1752\n",
      "Epoch: 1/1... Training loss: 0.1710\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1694\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1707\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1076\n",
      "Epoch: 1/1... Training loss: 0.1845\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1617\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1610\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1657\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1815\n",
      "Epoch: 1/1... Training loss: 0.1635\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.0999\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1682\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1654\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1669\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1011\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1678\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1651\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1519\n",
      "Epoch: 1/1... Training loss: 0.1645\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1838\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1599\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1714\n",
      "Epoch: 1/1... Training loss: 0.1898\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1563\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1676\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1064\n",
      "Epoch: 1/1... Training loss: 0.1064\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.0803\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1707\n",
      "Epoch: 1/1... Training loss: 0.0907\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1806\n",
      "Epoch: 1/1... Training loss: 0.1990\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1728\n",
      "Epoch: 1/1... Training loss: 0.1782\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1654\n",
      "Epoch: 1/1... Training loss: 0.1810\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1582\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1674\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1785\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1727\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1720\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1092\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1726\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.0991\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1753\n",
      "Epoch: 1/1... Training loss: 0.1587\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1611\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1660\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1610\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1840\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1756\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1814\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.0891\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1703\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1785\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1641\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1757\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1824\n",
      "Epoch: 1/1... Training loss: 0.1626\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.0954\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1089\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1065\n",
      "Epoch: 1/1... Training loss: 0.1688\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1679\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1738\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1688\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1655\n",
      "Epoch: 1/1... Training loss: 0.2020\n",
      "Epoch: 1/1... Training loss: 0.1664\n",
      "Epoch: 1/1... Training loss: 0.1776\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1799\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1666\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.2004\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1952\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1095\n",
      "Epoch: 1/1... Training loss: 0.1666\n",
      "Epoch: 1/1... Training loss: 0.0888\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1710\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1692\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.2100\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1745\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1656\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1881\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1880\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1679\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1609\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1696\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1865\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1830\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1655\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1626\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1027\n",
      "Epoch: 1/1... Training loss: 0.1774\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.1703\n",
      "Epoch: 1/1... Training loss: 0.1623\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1713\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1647\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1659\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1732\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1621\n",
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.0914\n",
      "Epoch: 1/1... Training loss: 0.1615\n",
      "Epoch: 1/1... Training loss: 0.1657\n",
      "Epoch: 1/1... Training loss: 0.1804\n",
      "Epoch: 1/1... Training loss: 0.0996\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1573\n",
      "Epoch: 1/1... Training loss: 0.0944\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1681\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.0803\n",
      "Epoch: 1/1... Training loss: 0.1874\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.0976\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1901\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1127\n",
      "Epoch: 1/1... Training loss: 0.1720\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1603\n",
      "Epoch: 1/1... Training loss: 0.1634\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1707\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.0946\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1691\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1787\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1684\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.1065\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1816\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1801\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1065\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1091\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1953\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1059\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1611\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1860\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1775\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1604\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1652\n",
      "Epoch: 1/1... Training loss: 0.1044\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1791\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1732\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1809\n",
      "Epoch: 1/1... Training loss: 0.1697\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1981\n",
      "Epoch: 1/1... Training loss: 0.1868\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.0964\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1702\n",
      "Epoch: 1/1... Training loss: 0.1765\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1815\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1692\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.0831\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1711\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1818\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1021\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1711\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1625\n",
      "Epoch: 1/1... Training loss: 0.1707\n",
      "Epoch: 1/1... Training loss: 0.1680\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1774\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1710\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1618\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1792\n",
      "Epoch: 1/1... Training loss: 0.1112\n",
      "Epoch: 1/1... Training loss: 0.1757\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1657\n",
      "Epoch: 1/1... Training loss: 0.1615\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.0971\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1716\n",
      "Epoch: 1/1... Training loss: 0.1838\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1842\n",
      "Epoch: 1/1... Training loss: 0.1680\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1627\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1741\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1610\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1683\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1690\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1744\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1579\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1025\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.0941\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1020\n",
      "Epoch: 1/1... Training loss: 0.1699\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1712\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1663\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1807\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1597\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1645\n",
      "Epoch: 1/1... Training loss: 0.1876\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1653\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1807\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.0846\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1616\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1060\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1671\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.2081\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1629\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1032\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.0935\n",
      "Epoch: 1/1... Training loss: 0.0990\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1601\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1735\n",
      "Epoch: 1/1... Training loss: 0.1671\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1639\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1848\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.0835\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1054\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1727\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1987\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1615\n",
      "Epoch: 1/1... Training loss: 0.1791\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1645\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1672\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1842\n",
      "Epoch: 1/1... Training loss: 0.1617\n",
      "Epoch: 1/1... Training loss: 0.1016\n",
      "Epoch: 1/1... Training loss: 0.1732\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1083\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1911\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.0910\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.0866\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1763\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1786\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1785\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1665\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1573\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1924\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1620\n",
      "Epoch: 1/1... Training loss: 0.1662\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1083\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.0966\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1654\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1633\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.0817\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1561\n",
      "Epoch: 1/1... Training loss: 0.1960\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1911\n",
      "Epoch: 1/1... Training loss: 0.1689\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1147\n",
      "Epoch: 1/1... Training loss: 0.1868\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1597\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1682\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1698\n",
      "Epoch: 1/1... Training loss: 0.1778\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1639\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1062\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1008\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.0844\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.0941\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1678\n",
      "Epoch: 1/1... Training loss: 0.1743\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1618\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.0904\n",
      "Epoch: 1/1... Training loss: 0.1690\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1671\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1663\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1647\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1553\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1114\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1655\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1027\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1047\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.0876\n",
      "Epoch: 1/1... Training loss: 0.1685\n",
      "Epoch: 1/1... Training loss: 0.1659\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1679\n",
      "Epoch: 1/1... Training loss: 0.1031\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1024\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1799\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1686\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.1041\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1672\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.1726\n",
      "Epoch: 1/1... Training loss: 0.1129\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1832\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1597\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.0861\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1750\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.0872\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1101\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1626\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1743\n",
      "Epoch: 1/1... Training loss: 0.1639\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1604\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1616\n",
      "Epoch: 1/1... Training loss: 0.0972\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1803\n",
      "Epoch: 1/1... Training loss: 0.0998\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1828\n",
      "Epoch: 1/1... Training loss: 0.1579\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1822\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1633\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1635\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.1703\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.0868\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1886\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1076\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1867\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1147\n",
      "Epoch: 1/1... Training loss: 0.1642\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.0941\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1021\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1672\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.0958\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1676\n",
      "Epoch: 1/1... Training loss: 0.1663\n",
      "Epoch: 1/1... Training loss: 0.1758\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1627\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1519\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1731\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1051\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1602\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.0903\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.0921\n",
      "Epoch: 1/1... Training loss: 0.1096\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1656\n",
      "Epoch: 1/1... Training loss: 0.1743\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1750\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.0817\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1610\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1766\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1765\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1727\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1680\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1711\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1699\n",
      "Epoch: 1/1... Training loss: 0.1114\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1000\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1897\n",
      "Epoch: 1/1... Training loss: 0.1323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1081\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1611\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.1693\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1798\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.2091\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.0817\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1808\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1897\n",
      "Epoch: 1/1... Training loss: 0.1756\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.0927\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.0966\n",
      "Epoch: 1/1... Training loss: 0.0992\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1711\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1707\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1697\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1086\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1677\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1882\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1679\n",
      "Epoch: 1/1... Training loss: 0.1120\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1617\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1607\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1689\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1620\n",
      "Epoch: 1/1... Training loss: 0.1838\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.0909\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1763\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1735\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1090\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1120\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1601\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1768\n",
      "Epoch: 1/1... Training loss: 0.1582\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.0906\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.0984\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1735\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1727\n",
      "Epoch: 1/1... Training loss: 0.1817\n",
      "Epoch: 1/1... Training loss: 0.1691\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.0938\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1665\n",
      "Epoch: 1/1... Training loss: 0.1639\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1597\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1673\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1591\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1609\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.0960\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1731\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1866\n",
      "Epoch: 1/1... Training loss: 0.0953\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1591\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1077\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1882\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.0817\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1752\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1096\n",
      "Epoch: 1/1... Training loss: 0.0974\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1821\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1930\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.0988\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1659\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1666\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.0781\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1680\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1672\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1023\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1579\n",
      "Epoch: 1/1... Training loss: 0.1098\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1657\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.0937\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1601\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.0935\n",
      "Epoch: 1/1... Training loss: 0.1966\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1048\n",
      "Epoch: 1/1... Training loss: 0.1644\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1654\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.0919\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1095\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1669\n",
      "Epoch: 1/1... Training loss: 0.0982\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.0968\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1017\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1579\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1009\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1682\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1838\n",
      "Epoch: 1/1... Training loss: 0.0970\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.0773\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1626\n",
      "Epoch: 1/1... Training loss: 0.1797\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1692\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1100\n",
      "Epoch: 1/1... Training loss: 0.1607\n",
      "Epoch: 1/1... Training loss: 0.1023\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1891\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.1007\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.0972\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1601\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1729\n",
      "Epoch: 1/1... Training loss: 0.1601\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1603\n",
      "Epoch: 1/1... Training loss: 0.1931\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1681\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.0988\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1091\n",
      "Epoch: 1/1... Training loss: 0.1047\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1725\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1074\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1719\n",
      "Epoch: 1/1... Training loss: 0.1705\n",
      "Epoch: 1/1... Training loss: 0.1746\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1682\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1720\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1153\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1732\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1845\n",
      "Epoch: 1/1... Training loss: 0.1807\n",
      "Epoch: 1/1... Training loss: 0.1783\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1677\n",
      "Epoch: 1/1... Training loss: 0.1690\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1001\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1587\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1717\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1852\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.0859\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1841\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1032\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1950\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1601\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1127\n",
      "Epoch: 1/1... Training loss: 0.1738\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1641\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1704\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1005\n",
      "Epoch: 1/1... Training loss: 0.2166\n",
      "Epoch: 1/1... Training loss: 0.1825\n",
      "Epoch: 1/1... Training loss: 0.1030\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1582\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1016\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1604\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1620\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1625\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1035\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1032\n",
      "Epoch: 1/1... Training loss: 0.1754\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1871\n",
      "Epoch: 1/1... Training loss: 0.1687\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.0920\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1620\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1645\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1841\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1587\n",
      "Epoch: 1/1... Training loss: 0.1684\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1516\n",
      "Epoch: 1/1... Training loss: 0.0928\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1740\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1642\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1060\n",
      "Epoch: 1/1... Training loss: 0.0878\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1627\n",
      "Epoch: 1/1... Training loss: 0.1633\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1790\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1720\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1653\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1561\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1698\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1715\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.0964\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1913\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1060\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1833\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1553\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1043\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1697\n",
      "Epoch: 1/1... Training loss: 0.1028\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1096\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1086\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1744\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1031\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1679\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.0867\n",
      "Epoch: 1/1... Training loss: 0.1639\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.0989\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1782\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1712\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1672\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.0920\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1889\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1695\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1720\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1037\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.0787\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.1599\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.0880\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1025\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1621\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1856\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1625\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.0835\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.0811\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.0945\n",
      "Epoch: 1/1... Training loss: 0.1127\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1641\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.0772\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1767\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1107\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1753\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1867\n",
      "Epoch: 1/1... Training loss: 0.0837\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1081\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1752\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1832\n",
      "Epoch: 1/1... Training loss: 0.1716\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1681\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.0889\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.0656\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1005\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1601\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.0841\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.0806\n",
      "Epoch: 1/1... Training loss: 0.1072\n",
      "Epoch: 1/1... Training loss: 0.1930\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1769\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1728\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.0984\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1755\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.0958\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1083\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.0962\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1063\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1081\n",
      "Epoch: 1/1... Training loss: 0.0973\n",
      "Epoch: 1/1... Training loss: 0.1516\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1010\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1791\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.0935\n",
      "Epoch: 1/1... Training loss: 0.1748\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1704\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1607\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.0773\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.0909\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1713\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1563\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1018\n",
      "Epoch: 1/1... Training loss: 0.1563\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1757\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1770\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1659\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.0939\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1685\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1754\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1926\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.0902\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1702\n",
      "Epoch: 1/1... Training loss: 0.1042\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1704\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.0807\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.0767\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1714\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.0871\n",
      "Epoch: 1/1... Training loss: 0.0743\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1031\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1724\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1699\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1760\n",
      "Epoch: 1/1... Training loss: 0.1673\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1774\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1095\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1089\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1051\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1017\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1601\n",
      "Epoch: 1/1... Training loss: 0.1669\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1785\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1089\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1804\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1561\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1561\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1129\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1091\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1093\n",
      "Epoch: 1/1... Training loss: 0.1717\n",
      "Epoch: 1/1... Training loss: 0.1617\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1643\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1725\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1826\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.0860\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1711\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1603\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1679\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1776\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.0887\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1029\n",
      "Epoch: 1/1... Training loss: 0.1041\n",
      "Epoch: 1/1... Training loss: 0.1641\n",
      "Epoch: 1/1... Training loss: 0.0998\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1664\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1010\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1746\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1688\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1008\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.0916\n",
      "Epoch: 1/1... Training loss: 0.1059\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1730\n",
      "Epoch: 1/1... Training loss: 0.1090\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1065\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.0866\n",
      "Epoch: 1/1... Training loss: 0.1707\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1653\n",
      "Epoch: 1/1... Training loss: 0.1690\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1713\n",
      "Epoch: 1/1... Training loss: 0.0895\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1739\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.1862\n",
      "Epoch: 1/1... Training loss: 0.1868\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.0937\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1769\n",
      "Epoch: 1/1... Training loss: 0.0899\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1018\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1056\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1022\n",
      "Epoch: 1/1... Training loss: 0.1001\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1582\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.0954\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1937\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1042\n",
      "Epoch: 1/1... Training loss: 0.1840\n",
      "Epoch: 1/1... Training loss: 0.0940\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1644\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1569\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1001\n",
      "Epoch: 1/1... Training loss: 0.0943\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.0798\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.0936\n",
      "Epoch: 1/1... Training loss: 0.1766\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1573\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1042\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1693\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1005\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1886\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1699\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1635\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.0983\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1059\n",
      "Epoch: 1/1... Training loss: 0.1114\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.1091\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1634\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1604\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1773\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.0852\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1667\n",
      "Epoch: 1/1... Training loss: 0.0880\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1081\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1012\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1089\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.0935\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1045\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1091\n",
      "Epoch: 1/1... Training loss: 0.0969\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1709\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1651\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1064\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1802\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1098\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.0683\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1886\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.0999\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1073\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1697\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1811\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1018\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1024\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1093\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1579\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1042\n",
      "Epoch: 1/1... Training loss: 0.1615\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1645\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1082\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1776\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.0963\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.0858\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1803\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1817\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1005\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1639\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1618\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1615\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.0886\n",
      "Epoch: 1/1... Training loss: 0.1712\n",
      "Epoch: 1/1... Training loss: 0.1915\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.2044\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.0577\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1795\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.0864\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1674\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1519\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1604\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1100\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.0960\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1092\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1579\n",
      "Epoch: 1/1... Training loss: 0.0965\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1072\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1731\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1716\n",
      "Epoch: 1/1... Training loss: 0.1599\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1519\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.0971\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1665\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.0827\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.0998\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.0980\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1012\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1732\n",
      "Epoch: 1/1... Training loss: 0.0868\n",
      "Epoch: 1/1... Training loss: 0.0950\n",
      "Epoch: 1/1... Training loss: 0.1607\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1028\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.0903\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.0639\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1775\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1645\n",
      "Epoch: 1/1... Training loss: 0.0910\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1129\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.0982\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1112\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1617\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.0896\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1076\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1694\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1696\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1027\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1129\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1012\n",
      "Epoch: 1/1... Training loss: 0.1610\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1662\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1633\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1591\n",
      "Epoch: 1/1... Training loss: 0.1764\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1701\n",
      "Epoch: 1/1... Training loss: 0.1615\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1696\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1120\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1625\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1006\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1031\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1663\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.0861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1698\n",
      "Epoch: 1/1... Training loss: 0.0740\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1615\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.0921\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1782\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1054\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1091\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1933\n",
      "Epoch: 1/1... Training loss: 0.1032\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1050\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1681\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1651\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1008\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.0908\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.0975\n",
      "Epoch: 1/1... Training loss: 0.1602\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1033\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1647\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.1683\n",
      "Epoch: 1/1... Training loss: 0.1639\n",
      "Epoch: 1/1... Training loss: 0.1895\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1724\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1725\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1694\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1895\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1098\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1712\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1721\n",
      "Epoch: 1/1... Training loss: 0.1017\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1044\n",
      "Epoch: 1/1... Training loss: 0.1672\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1650\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1153\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1117\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1573\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1728\n",
      "Epoch: 1/1... Training loss: 0.0916\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1873\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1030\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1689\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1053\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1736\n",
      "Epoch: 1/1... Training loss: 0.1604\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.0971\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1012\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1700\n",
      "Epoch: 1/1... Training loss: 0.0995\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1682\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1657\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1701\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1776\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.0973\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1604\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1697\n",
      "Epoch: 1/1... Training loss: 0.0876\n",
      "Epoch: 1/1... Training loss: 0.1686\n",
      "Epoch: 1/1... Training loss: 0.1694\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1646\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1010\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1609\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1776\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1563\n",
      "Epoch: 1/1... Training loss: 0.1862\n",
      "Epoch: 1/1... Training loss: 0.0927\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1009\n",
      "Epoch: 1/1... Training loss: 0.1813\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1753\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1837\n",
      "Epoch: 1/1... Training loss: 0.1644\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1013\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1796\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.0939\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1677\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.0887\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1710\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.0954\n",
      "Epoch: 1/1... Training loss: 0.0949\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1926\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1804\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1098\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1716\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1587\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1010\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1602\n",
      "Epoch: 1/1... Training loss: 0.0919\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1599\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1009\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.0941\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1617\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1756\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1129\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1727\n",
      "Epoch: 1/1... Training loss: 0.1681\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1790\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.0946\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.0931\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1009\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1691\n",
      "Epoch: 1/1... Training loss: 0.0713\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.0943\n",
      "Epoch: 1/1... Training loss: 0.1623\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1790\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1720\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1039\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.0990\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.0975\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1015\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1093\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1071\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1090\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.0974\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.0959\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.0942\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.0905\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1697\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.0976\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1077\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1077\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1703\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1059\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.0946\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1639\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.0958\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1034\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1656\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1705\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1634\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.0942\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1129\n",
      "Epoch: 1/1... Training loss: 0.1910\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.0966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1750\n",
      "Epoch: 1/1... Training loss: 0.1597\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1573\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1603\n",
      "Epoch: 1/1... Training loss: 0.1030\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1627\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1617\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1659\n",
      "Epoch: 1/1... Training loss: 0.1038\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1676\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1044\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1858\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1618\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1643\n",
      "Epoch: 1/1... Training loss: 0.1009\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1072\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.0968\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1626\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1627\n",
      "Epoch: 1/1... Training loss: 0.1081\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1689\n",
      "Epoch: 1/1... Training loss: 0.1602\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1688\n",
      "Epoch: 1/1... Training loss: 0.0565\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.0966\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.0831\n",
      "Epoch: 1/1... Training loss: 0.0967\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1694\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1003\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1734\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.2154\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1702\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1093\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1012\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1582\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.0982\n",
      "Epoch: 1/1... Training loss: 0.0943\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1735\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1587\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.0715\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1599\n",
      "Epoch: 1/1... Training loss: 0.1736\n",
      "Epoch: 1/1... Training loss: 0.0986\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.0993\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1700\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1714\n",
      "Epoch: 1/1... Training loss: 0.0984\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1059\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1696\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1674\n",
      "Epoch: 1/1... Training loss: 0.1050\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.0876\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1657\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1101\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1723\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1041\n",
      "Epoch: 1/1... Training loss: 0.1616\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.0992\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1720\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1627\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.0908\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.0976\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.0862\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1054\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.0906\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1591\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1690\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1069\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1718\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1708\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1677\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1117\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.0938\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1074\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1627\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1709\n",
      "Epoch: 1/1... Training loss: 0.1641\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1045\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1091\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.0859\n",
      "Epoch: 1/1... Training loss: 0.1034\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.0887\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.0963\n",
      "Epoch: 1/1... Training loss: 0.1617\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1849\n",
      "Epoch: 1/1... Training loss: 0.1875\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1563\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1098\n",
      "Epoch: 1/1... Training loss: 0.0743\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1772\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1602\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1692\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.0703\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1720\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1127\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1799\n",
      "Epoch: 1/1... Training loss: 0.0975\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1748\n",
      "Epoch: 1/1... Training loss: 0.1064\n",
      "Epoch: 1/1... Training loss: 0.1708\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1012\n",
      "Epoch: 1/1... Training loss: 0.1727\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1729\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1820\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.0993\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1689\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1749\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1023\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.0902\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.0931\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.0943\n",
      "Epoch: 1/1... Training loss: 0.0909\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1599\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.1101\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1001\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.0932\n",
      "Epoch: 1/1... Training loss: 0.1660\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1092\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.0915\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1680\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1039\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.0907\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.0968\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1709\n",
      "Epoch: 1/1... Training loss: 0.1573\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1090\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.0948\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1053\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1032\n",
      "Epoch: 1/1... Training loss: 0.1051\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1008\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1644\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1653\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.1776\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.0996\n",
      "Epoch: 1/1... Training loss: 0.0845\n",
      "Epoch: 1/1... Training loss: 0.1827\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1878\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1713\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1025\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.0912\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1069\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1611\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1051\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1063\n",
      "Epoch: 1/1... Training loss: 0.1656\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1777\n",
      "Epoch: 1/1... Training loss: 0.1073\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.0944\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1742\n",
      "Epoch: 1/1... Training loss: 0.1068\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.0820\n",
      "Epoch: 1/1... Training loss: 0.1758\n",
      "Epoch: 1/1... Training loss: 0.0858\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1688\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.0829\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1773\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1054\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.0927\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.0858\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1602\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1112\n",
      "Epoch: 1/1... Training loss: 0.1015\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1769\n",
      "Epoch: 1/1... Training loss: 0.0977\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1107\n",
      "Epoch: 1/1... Training loss: 0.1021\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1129\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1073\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1771\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1120\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1037\n",
      "Epoch: 1/1... Training loss: 0.1003\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1067\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1623\n",
      "Epoch: 1/1... Training loss: 0.1705\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1077\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1691\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1053\n",
      "Epoch: 1/1... Training loss: 0.0994\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1034\n",
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1651\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1056\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1635\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1718\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1030\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1617\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1043\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1671\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1018\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1643\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1029\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1056\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.0982\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1089\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1635\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1718\n",
      "Epoch: 1/1... Training loss: 0.1591\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1682\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.0669\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.0966\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1081\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1652\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1793\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1043\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.0809\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.1009\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1602\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1641\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1067\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1618\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1849\n",
      "Epoch: 1/1... Training loss: 0.1625\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1516\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1607\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.0923\n",
      "Epoch: 1/1... Training loss: 0.0980\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1008\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1618\n",
      "Epoch: 1/1... Training loss: 0.0896\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1616\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.0936\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.0978\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1844\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1845\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1781\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.0909\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1927\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1680\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1761\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1690\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1761\n",
      "Epoch: 1/1... Training loss: 0.1700\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.0879\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1825\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1093\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1091\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1651\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1006\n",
      "Epoch: 1/1... Training loss: 0.1662\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1065\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.1044\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1035\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1787\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1678\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1091\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1646\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.0849\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1607\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1814\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1081\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.0923\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1861\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1725\n",
      "Epoch: 1/1... Training loss: 0.0959\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1760\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.0975\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1701\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1634\n",
      "Epoch: 1/1... Training loss: 0.1043\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1028\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1698\n",
      "Epoch: 1/1... Training loss: 0.1004\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1095\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1587\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.0953\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.0877\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.0982\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1652\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1723\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1629\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1765\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1804\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1621\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.2013\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1068\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.0959\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1048\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1069\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1019\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1038\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.0901\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.0852\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1027\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.0972\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1654\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1067\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.2147\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1763\n",
      "Epoch: 1/1... Training loss: 0.1014\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.0868\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1851\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1033\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1680\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1609\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.0936\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1634\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1722\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1601\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1516\n",
      "Epoch: 1/1... Training loss: 0.1677\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1618\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.0916\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1752\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.0705\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.0906\n",
      "Epoch: 1/1... Training loss: 0.1764\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1721\n",
      "Epoch: 1/1... Training loss: 0.1052\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1052\n",
      "Epoch: 1/1... Training loss: 0.1664\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1871\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.0820\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1064\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1639\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1710\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1691\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.0973\n",
      "Epoch: 1/1... Training loss: 0.0955\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.0983\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.0963\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1822\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1610\n",
      "Epoch: 1/1... Training loss: 0.1641\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1090\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1687\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.0865\n",
      "Epoch: 1/1... Training loss: 0.1091\n",
      "Epoch: 1/1... Training loss: 0.1657\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.0961\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1684\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1024\n",
      "Epoch: 1/1... Training loss: 0.1828\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1022\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1635\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1653\n",
      "Epoch: 1/1... Training loss: 0.1052\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.0998\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1519\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1814\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1064\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1069\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1074\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1147\n",
      "Epoch: 1/1... Training loss: 0.1051\n",
      "Epoch: 1/1... Training loss: 0.0637\n",
      "Epoch: 1/1... Training loss: 0.0885\n",
      "Epoch: 1/1... Training loss: 0.1074\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1880\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.0952\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1045\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1587\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1694\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.0927\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1019\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1120\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1656\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1101\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1808\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1712\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1647\n",
      "Epoch: 1/1... Training loss: 0.1671\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1965\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.1076\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1038\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1021\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.2017\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1038\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.0941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.0986\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1681\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1778\n",
      "Epoch: 1/1... Training loss: 0.0990\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.0887\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1069\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1010\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.0940\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1767\n",
      "Epoch: 1/1... Training loss: 0.1647\n",
      "Epoch: 1/1... Training loss: 0.0955\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1041\n",
      "Epoch: 1/1... Training loss: 0.0939\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.0996\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.0620\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.0985\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1677\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.0968\n",
      "Epoch: 1/1... Training loss: 0.1623\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1659\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.0865\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1601\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1090\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1117\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1752\n",
      "Epoch: 1/1... Training loss: 0.1092\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.0835\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.0945\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1516\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.0852\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1014\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.0964\n",
      "Epoch: 1/1... Training loss: 0.1749\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1064\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1093\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1602\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1669\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.0879\n",
      "Epoch: 1/1... Training loss: 0.1036\n",
      "Epoch: 1/1... Training loss: 0.1703\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1651\n",
      "Epoch: 1/1... Training loss: 0.1077\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1582\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1715\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1702\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1705\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1715\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1107\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.0737\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.0923\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.0890\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1749\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1127\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.0946\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1029\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.0834\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1053\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1038\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1874\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1120\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1602\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1098\n",
      "Epoch: 1/1... Training loss: 0.1032\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1635\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1779\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1561\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.0851\n",
      "Epoch: 1/1... Training loss: 0.1092\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.0862\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.0934\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1656\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1072\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.0971\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1062\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.0880\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1044\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1014\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1761\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1045\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1880\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1553\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1013\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1607\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1022\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1875\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1676\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1095\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1076\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1582\n",
      "Epoch: 1/1... Training loss: 0.1092\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.0795\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1750\n",
      "Epoch: 1/1... Training loss: 0.0976\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.0916\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1050\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1587\n",
      "Epoch: 1/1... Training loss: 0.1740\n",
      "Epoch: 1/1... Training loss: 0.1048\n",
      "Epoch: 1/1... Training loss: 0.1700\n",
      "Epoch: 1/1... Training loss: 0.1004\n",
      "Epoch: 1/1... Training loss: 0.1039\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1654\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.0865\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1711\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1052\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.2173\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1660\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.0971\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1796\n",
      "Epoch: 1/1... Training loss: 0.1643\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1023\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1117\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.0779\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1645\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1044\n",
      "Epoch: 1/1... Training loss: 0.1050\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1579\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.0988\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1843\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1604\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.0953\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1052\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1752\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.0965\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.0974\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1644\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1851\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1635\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1114\n",
      "Epoch: 1/1... Training loss: 0.1127\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1048\n",
      "Epoch: 1/1... Training loss: 0.1000\n",
      "Epoch: 1/1... Training loss: 0.1561\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1633\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1100\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.0899\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1101\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1720\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1734\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1101\n",
      "Epoch: 1/1... Training loss: 0.1618\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1690\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1077\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.0929\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1708\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1656\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1694\n",
      "Epoch: 1/1... Training loss: 0.1072\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1683\n",
      "Epoch: 1/1... Training loss: 0.1655\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1652\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1735\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.0913\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.1076\n",
      "Epoch: 1/1... Training loss: 0.1731\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1090\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1048\n",
      "Epoch: 1/1... Training loss: 0.1043\n",
      "Epoch: 1/1... Training loss: 0.1008\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1755\n",
      "Epoch: 1/1... Training loss: 0.0901\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1692\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1603\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1032\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1127\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1635\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1062\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1650\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.0954\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1065\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.0927\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1035\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1069\n",
      "Epoch: 1/1... Training loss: 0.1875\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1072\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.0777\n",
      "Epoch: 1/1... Training loss: 0.0901\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.0906\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1928\n",
      "Epoch: 1/1... Training loss: 0.1009\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1038\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1650\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1076\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1617\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1081\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1117\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1601\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.0955\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1051\n",
      "Epoch: 1/1... Training loss: 0.1032\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1034\n",
      "Epoch: 1/1... Training loss: 0.0991\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1744\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1059\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1003\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1680\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1052\n",
      "Epoch: 1/1... Training loss: 0.1044\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.0999\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.0965\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.0824\n",
      "Epoch: 1/1... Training loss: 0.1635\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1597\n",
      "Epoch: 1/1... Training loss: 0.1633\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1738\n",
      "Epoch: 1/1... Training loss: 0.1016\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1096\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.0953\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1610\n",
      "Epoch: 1/1... Training loss: 0.1101\n",
      "Epoch: 1/1... Training loss: 0.1696\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1726\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1093\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.0969\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1056\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.0884\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1579\n",
      "Epoch: 1/1... Training loss: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1674\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1153\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.0930\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.0969\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.1872\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.0855\n",
      "Epoch: 1/1... Training loss: 0.1934\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1029\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1686\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.0776\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.0941\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.0931\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1076\n",
      "Epoch: 1/1... Training loss: 0.0924\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1107\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1007\n",
      "Epoch: 1/1... Training loss: 0.1065\n",
      "Epoch: 1/1... Training loss: 0.1651\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1728\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1703\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1714\n",
      "Epoch: 1/1... Training loss: 0.1000\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1616\n",
      "Epoch: 1/1... Training loss: 0.1667\n",
      "Epoch: 1/1... Training loss: 0.0965\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1020\n",
      "Epoch: 1/1... Training loss: 0.1634\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1034\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1073\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1641\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.0922\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1618\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.0906\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1691\n",
      "Epoch: 1/1... Training loss: 0.1086\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1768\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.0898\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1107\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.0808\n",
      "Epoch: 1/1... Training loss: 0.1020\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.0858\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1004\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1047\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1053\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1748\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.0884\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.0738\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1775\n",
      "Epoch: 1/1... Training loss: 0.0856\n",
      "Epoch: 1/1... Training loss: 0.1096\n",
      "Epoch: 1/1... Training loss: 0.1617\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1035\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1814\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1013\n",
      "Epoch: 1/1... Training loss: 0.1100\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.0975\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.0896\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1100\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1073\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1093\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.0984\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.0966\n",
      "Epoch: 1/1... Training loss: 0.0637\n",
      "Epoch: 1/1... Training loss: 0.1709\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.0995\n",
      "Epoch: 1/1... Training loss: 0.0975\n",
      "Epoch: 1/1... Training loss: 0.0863\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1728\n",
      "Epoch: 1/1... Training loss: 0.0925\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1129\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1735\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1573\n",
      "Epoch: 1/1... Training loss: 0.0865\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1732\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.0934\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.0968\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1688\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1093\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.0984\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1706\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.0819\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1659\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.0994\n",
      "Epoch: 1/1... Training loss: 0.1050\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1010\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.0936\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1090\n",
      "Epoch: 1/1... Training loss: 0.0935\n",
      "Epoch: 1/1... Training loss: 0.1019\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1710\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.0806\n",
      "Epoch: 1/1... Training loss: 0.0970\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1646\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1621\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1027\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.0813\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1747\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.0844\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1749\n",
      "Epoch: 1/1... Training loss: 0.1734\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1004\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.1030\n",
      "Epoch: 1/1... Training loss: 0.1117\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1611\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1011\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1074\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1147\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1147\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1007\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.0999\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.0972\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1086\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1101\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.0984\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1579\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1710\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.0992\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1746\n",
      "Epoch: 1/1... Training loss: 0.0970\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1753\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.0855\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1869\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.0965\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1033\n",
      "Epoch: 1/1... Training loss: 0.0975\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.0854\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.0845\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1042\n",
      "Epoch: 1/1... Training loss: 0.1720\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1621\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1688\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.0987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1068\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1722\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1642\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1002\n",
      "Epoch: 1/1... Training loss: 0.1051\n",
      "Epoch: 1/1... Training loss: 0.0829\n",
      "Epoch: 1/1... Training loss: 0.1052\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1777\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1101\n",
      "Epoch: 1/1... Training loss: 0.1634\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.0999\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1020\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1147\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1006\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1000\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1695\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.0990\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.0845\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1769\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1052\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.0976\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.0944\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1076\n",
      "Epoch: 1/1... Training loss: 0.0858\n",
      "Epoch: 1/1... Training loss: 0.1093\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1005\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1678\n",
      "Epoch: 1/1... Training loss: 0.1043\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.0994\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.0893\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1020\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.0901\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1107\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1888\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1692\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1008\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.0781\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1633\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1725\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.0943\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1906\n",
      "Epoch: 1/1... Training loss: 0.0927\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1112\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1096\n",
      "Epoch: 1/1... Training loss: 0.1048\n",
      "Epoch: 1/1... Training loss: 0.1071\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.0922\n",
      "Epoch: 1/1... Training loss: 0.1043\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1841\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.0757\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.0921\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.0912\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1071\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1037\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1037\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.0911\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1114\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1516\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1101\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1051\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1725\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.0943\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.0788\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1788\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.0986\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1563\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1766\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.0940\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1659\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.0915\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1736\n",
      "Epoch: 1/1... Training loss: 0.1806\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.0990\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1729\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.0982\n",
      "Epoch: 1/1... Training loss: 0.1987\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1607\n",
      "Epoch: 1/1... Training loss: 0.1077\n",
      "Epoch: 1/1... Training loss: 0.0928\n",
      "Epoch: 1/1... Training loss: 0.1023\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1114\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1662\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1654\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.0890\n",
      "Epoch: 1/1... Training loss: 0.0919\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1599\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.0863\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1634\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1819\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.0920\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.0798\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1010\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.2100\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1669\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1669\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1008\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1599\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1012\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1090\n",
      "Epoch: 1/1... Training loss: 0.1654\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1063\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.0860\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.0849\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1666\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1003\n",
      "Epoch: 1/1... Training loss: 0.1833\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1663\n",
      "Epoch: 1/1... Training loss: 0.1063\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1090\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1623\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.0910\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1129\n",
      "Epoch: 1/1... Training loss: 0.1002\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1028\n",
      "Epoch: 1/1... Training loss: 0.0991\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.0912\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1664\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.1682\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.0993\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.2092\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1092\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1779\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1610\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1038\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1032\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1033\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.0996\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1073\n",
      "Epoch: 1/1... Training loss: 0.1153\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1781\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1044\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1054\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1117\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1819\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1618\n",
      "Epoch: 1/1... Training loss: 0.1073\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1759\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1735\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.0911\n",
      "Epoch: 1/1... Training loss: 0.1072\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.0811\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1064\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1818\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.0958\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1112\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1098\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1677\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.0941\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1813\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1009\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1811\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.0900\n",
      "Epoch: 1/1... Training loss: 0.0987\n",
      "Epoch: 1/1... Training loss: 0.1024\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1096\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1579\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.0903\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1062\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1768\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1689\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.0959\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.0973\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1735\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1120\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1682\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.0982\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1807\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.0954\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1609\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1068\n",
      "Epoch: 1/1... Training loss: 0.1147\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1553\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1582\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.0955\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1751\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1056\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1101\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1641\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1731\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1710\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1582\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1678\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.0963\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1039\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.1021\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1096\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.0983\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.0867\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.0912\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1880\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1633\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1027\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.0955\n",
      "Epoch: 1/1... Training loss: 0.1129\n",
      "Epoch: 1/1... Training loss: 0.1516\n",
      "Epoch: 1/1... Training loss: 0.0981\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1665\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1645\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1011\n",
      "Epoch: 1/1... Training loss: 0.0839\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1054\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1001\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.0827\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1730\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1795\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1591\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.0934\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1834\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1025\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1018\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1516\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1043\n",
      "Epoch: 1/1... Training loss: 0.0957\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.0838\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1089\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.0928\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1153\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1091\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1691\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.0981\n",
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.0966\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1751\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1677\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1068\n",
      "Epoch: 1/1... Training loss: 0.1833\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1735\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1029\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.0998\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1014\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.0988\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1022\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1029\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.0969\n",
      "Epoch: 1/1... Training loss: 0.1582\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.0969\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1147\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1050\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1644\n",
      "Epoch: 1/1... Training loss: 0.0948\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1711\n",
      "Epoch: 1/1... Training loss: 0.1610\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1650\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1695\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1039\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1603\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1587\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1064\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.0971\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1647\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1643\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1001\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1708\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1127\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1086\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1674\n",
      "Epoch: 1/1... Training loss: 0.1107\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.0826\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1065\n",
      "Epoch: 1/1... Training loss: 0.1663\n",
      "Epoch: 1/1... Training loss: 0.0919\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1625\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1082\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1068\n",
      "Epoch: 1/1... Training loss: 0.1618\n",
      "Epoch: 1/1... Training loss: 0.0952\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1019\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1021\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.0914\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1705\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1031\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1587\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1147\n",
      "Epoch: 1/1... Training loss: 0.1734\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.0938\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1599\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1695\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1039\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1083\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1616\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1740\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.0949\n",
      "Epoch: 1/1... Training loss: 0.0962\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1698\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1751\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1074\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.0954\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1029\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.0838\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.0935\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1639\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1569\n",
      "Epoch: 1/1... Training loss: 0.1100\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1651\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.0984\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1786\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.0843\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1100\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1101\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1065\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1662\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1618\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.0753\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1096\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.0793\n",
      "Epoch: 1/1... Training loss: 0.1032\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.0976\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.0921\n",
      "Epoch: 1/1... Training loss: 0.1019\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1969\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.1082\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1692\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.0900\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1801\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1687\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.0981\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.0868\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1011\n",
      "Epoch: 1/1... Training loss: 0.1561\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1089\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1107\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1083\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.0985\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1653\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1002\n",
      "Epoch: 1/1... Training loss: 0.0860\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1117\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.0921\n",
      "Epoch: 1/1... Training loss: 0.1014\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1701\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.0726\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1757\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1054\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1664\n",
      "Epoch: 1/1... Training loss: 0.1072\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1720\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1020\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.0718\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1092\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1653\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1009\n",
      "Epoch: 1/1... Training loss: 0.1643\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1043\n",
      "Epoch: 1/1... Training loss: 0.1767\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1802\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.0959\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1076\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.0595\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1025\n",
      "Epoch: 1/1... Training loss: 0.0866\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.0961\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.1708\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1616\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1715\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1760\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1065\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.0992\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1656\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.0970\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1095\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1153\n",
      "Epoch: 1/1... Training loss: 0.0942\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1069\n",
      "Epoch: 1/1... Training loss: 0.1707\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1689\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.0982\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1001\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.0925\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1042\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1609\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1783\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.0968\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1098\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1107\n",
      "Epoch: 1/1... Training loss: 0.1573\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1719\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1623\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1006\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1726\n",
      "Epoch: 1/1... Training loss: 0.1609\n",
      "Epoch: 1/1... Training loss: 0.1050\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.0953\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1597\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1092\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.1643\n",
      "Epoch: 1/1... Training loss: 0.1733\n",
      "Epoch: 1/1... Training loss: 0.1678\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.0911\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1100\n",
      "Epoch: 1/1... Training loss: 0.0933\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1038\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1030\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1069\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.0955\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1666\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1603\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1029\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1005\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.0974\n",
      "Epoch: 1/1... Training loss: 0.1071\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1708\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1616\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1651\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1609\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1071\n",
      "Epoch: 1/1... Training loss: 0.1597\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.0982\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1100\n",
      "Epoch: 1/1... Training loss: 0.1684\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.0978\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1147\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1072\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1020\n",
      "Epoch: 1/1... Training loss: 0.0953\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1659\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1014\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.0941\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1083\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1002\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.0943\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.0894\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1591\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1768\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.0885\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1069\n",
      "Epoch: 1/1... Training loss: 0.1005\n",
      "Epoch: 1/1... Training loss: 0.1740\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1850\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1827\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1641\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.0641\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1672\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1112\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.0984\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1043\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.0972\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1027\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1004\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1083\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.0912\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1870\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1089\n",
      "Epoch: 1/1... Training loss: 0.1031\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.0954\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.0910\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.0907\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1077\n",
      "Epoch: 1/1... Training loss: 0.1018\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1786\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1727\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1609\n",
      "Epoch: 1/1... Training loss: 0.0922\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1736\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1519\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1707\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1737\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1059\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.0800\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1001\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1089\n",
      "Epoch: 1/1... Training loss: 0.1019\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1516\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.0739\n",
      "Epoch: 1/1... Training loss: 0.0912\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.0986\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.0974\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.0975\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1045\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1587\n",
      "Epoch: 1/1... Training loss: 0.1726\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.0989\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1038\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.0960\n",
      "Epoch: 1/1... Training loss: 0.1031\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1903\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1117\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1091\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.0851\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1092\n",
      "Epoch: 1/1... Training loss: 0.1553\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.0969\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.0971\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.0970\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1768\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.0927\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1081\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.0801\n",
      "Epoch: 1/1... Training loss: 0.0848\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1697\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1840\n",
      "Epoch: 1/1... Training loss: 0.0918\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1090\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1903\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.0870\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.0940\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1082\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1754\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.0903\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.0887\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.0991\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.0963\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1623\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1786\n",
      "Epoch: 1/1... Training loss: 0.1002\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1117\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.0968\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.0978\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.0996\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1003\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1081\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.0962\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1862\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.0999\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1516\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1701\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.0954\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1701\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1719\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.0879\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1034\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1095\n",
      "Epoch: 1/1... Training loss: 0.0973\n",
      "Epoch: 1/1... Training loss: 0.1812\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1101\n",
      "Epoch: 1/1... Training loss: 0.0781\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.0992\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.0796\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1001\n",
      "Epoch: 1/1... Training loss: 0.2145\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.0969\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1732\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1024\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.0963\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1696\n",
      "Epoch: 1/1... Training loss: 0.1038\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1603\n",
      "Epoch: 1/1... Training loss: 0.1045\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1626\n",
      "Epoch: 1/1... Training loss: 0.1633\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1012\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1635\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1599\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1064\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.0977\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1031\n",
      "Epoch: 1/1... Training loss: 0.1022\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1020\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1071\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.0985\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1803\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1712\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1859\n",
      "Epoch: 1/1... Training loss: 0.0804\n",
      "Epoch: 1/1... Training loss: 0.1875\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1563\n",
      "Epoch: 1/1... Training loss: 0.1050\n",
      "Epoch: 1/1... Training loss: 0.1047\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1008\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1019\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1015\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1752\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1045\n",
      "Epoch: 1/1... Training loss: 0.1060\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1751\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1223\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1098\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1050\n",
      "Epoch: 1/1... Training loss: 0.0962\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1569\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1041\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1710\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1729\n",
      "Epoch: 1/1... Training loss: 0.1045\n",
      "Epoch: 1/1... Training loss: 0.0974\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.0946\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.0967\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.1684\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1068\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1740\n",
      "Epoch: 1/1... Training loss: 0.1013\n",
      "Epoch: 1/1... Training loss: 0.1757\n",
      "Epoch: 1/1... Training loss: 0.0987\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1638\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1047\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1919\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1646\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.0932\n",
      "Epoch: 1/1... Training loss: 0.1650\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1098\n",
      "Epoch: 1/1... Training loss: 0.0975\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.0804\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.0994\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1014\n",
      "Epoch: 1/1... Training loss: 0.0947\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1819\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1071\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1013\n",
      "Epoch: 1/1... Training loss: 0.1072\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1092\n",
      "Epoch: 1/1... Training loss: 0.1017\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.0920\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1073\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.0812\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1660\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.2010\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1903\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1015\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.0951\n",
      "Epoch: 1/1... Training loss: 0.1037\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1019\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1056\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1657\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.0966\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1763\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1024\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1045\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1783\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1024\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1069\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1015\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.0961\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.0851\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1563\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1663\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1644\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1654\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.0781\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1654\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.0944\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1754\n",
      "Epoch: 1/1... Training loss: 0.1691\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1024\n",
      "Epoch: 1/1... Training loss: 0.1569\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1655\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1114\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1629\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.0938\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1062\n",
      "Epoch: 1/1... Training loss: 0.1041\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1711\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1691\n",
      "Epoch: 1/1... Training loss: 0.1711\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.0950\n",
      "Epoch: 1/1... Training loss: 0.1747\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1620\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1076\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.0967\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.0957\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1127\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1041\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.0973\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.0956\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1644\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1553\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.0649\n",
      "Epoch: 1/1... Training loss: 0.0889\n",
      "Epoch: 1/1... Training loss: 0.0963\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1001\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1519\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1129\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1063\n",
      "Epoch: 1/1... Training loss: 0.1013\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.0899\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.0906\n",
      "Epoch: 1/1... Training loss: 0.0937\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.0891\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1687\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1806\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1008\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.0934\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1732\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1688\n",
      "Epoch: 1/1... Training loss: 0.0839\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1553\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1095\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1129\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1018\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1074\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1802\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1050\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.0971\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1018\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.0940\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.0898\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1093\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1683\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1725\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1030\n",
      "Epoch: 1/1... Training loss: 0.1030\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1584\n",
      "Epoch: 1/1... Training loss: 0.1153\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.0995\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1698\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.0807\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1919\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1705\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1015\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1829\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.0993\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.0984\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1739\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1615\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.1818\n",
      "Epoch: 1/1... Training loss: 0.1674\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1553\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1015\n",
      "Epoch: 1/1... Training loss: 0.1677\n",
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1650\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1595\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.0964\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1747\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.0871\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1626\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.0876\n",
      "Epoch: 1/1... Training loss: 0.1096\n",
      "Epoch: 1/1... Training loss: 0.1021\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1015\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1020\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1702\n",
      "Epoch: 1/1... Training loss: 0.1660\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1047\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.0753\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1708\n",
      "Epoch: 1/1... Training loss: 0.1112\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1717\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1041\n",
      "Epoch: 1/1... Training loss: 0.1081\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1743\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.0759\n",
      "Epoch: 1/1... Training loss: 0.1735\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1607\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.0792\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.0913\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1028\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.0930\n",
      "Epoch: 1/1... Training loss: 0.1778\n",
      "Epoch: 1/1... Training loss: 0.1098\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1005\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.0988\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.0984\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1709\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.0961\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.0633\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1747\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.0962\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1112\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1667\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.0883\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.0856\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1629\n",
      "Epoch: 1/1... Training loss: 0.1690\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.0990\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.0969\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1597\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1065\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1052\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1689\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.0999\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1703\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1664\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.0975\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1025\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1832\n",
      "Epoch: 1/1... Training loss: 0.1673\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1655\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1679\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1615\n",
      "Epoch: 1/1... Training loss: 0.1652\n",
      "Epoch: 1/1... Training loss: 0.0913\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.0993\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.0928\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1032\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1759\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1563\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1035\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1045\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1731\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1153\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.0983\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1838\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.0961\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.0963\n",
      "Epoch: 1/1... Training loss: 0.1826\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.0981\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1732\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1651\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1048\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1667\n",
      "Epoch: 1/1... Training loss: 0.1588\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1090\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1022\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.0998\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1073\n",
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.0983\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1017\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.0961\n",
      "Epoch: 1/1... Training loss: 0.0895\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1037\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1664\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1073\n",
      "Epoch: 1/1... Training loss: 0.1038\n",
      "Epoch: 1/1... Training loss: 0.1096\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.0896\n",
      "Epoch: 1/1... Training loss: 0.1602\n",
      "Epoch: 1/1... Training loss: 0.0815\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1127\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1002\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1112\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1004\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.0942\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1650\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1758\n",
      "Epoch: 1/1... Training loss: 0.0846\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1003\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1589\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1682\n",
      "Epoch: 1/1... Training loss: 0.1569\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1774\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1064\n",
      "Epoch: 1/1... Training loss: 0.1611\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1025\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.0963\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1767\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1832\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1754\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1114\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1120\n",
      "Epoch: 1/1... Training loss: 0.1035\n",
      "Epoch: 1/1... Training loss: 0.1038\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.0703\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1898\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.0972\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1071\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1112\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1101\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.0989\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1064\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1604\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1112\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1014\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1610\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1716\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.0948\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.0984\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1120\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1735\n",
      "Epoch: 1/1... Training loss: 0.1100\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.0975\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.0975\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1114\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1037\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.0899\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.0974\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1792\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.0937\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.0897\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1082\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.0960\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.0867\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1029\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.0994\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.0840\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1722\n",
      "Epoch: 1/1... Training loss: 0.1120\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.0898\n",
      "Epoch: 1/1... Training loss: 0.1678\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.0967\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.0699\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.0929\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1030\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.0902\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.0972\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1627\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.0999\n",
      "Epoch: 1/1... Training loss: 0.1068\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1052\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.0764\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1150\n",
      "Epoch: 1/1... Training loss: 0.0901\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.0879\n",
      "Epoch: 1/1... Training loss: 0.1694\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1730\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1096\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.0967\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.0936\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.0976\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1015\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.0844\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1667\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1232\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.0872\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.0970\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.0977\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1034\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1774\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.0966\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.0952\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1024\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1019\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1016\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1932\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1720\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1563\n",
      "Epoch: 1/1... Training loss: 0.1481\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.0930\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1569\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.0952\n",
      "Epoch: 1/1... Training loss: 0.1715\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1676\n",
      "Epoch: 1/1... Training loss: 0.1100\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.0929\n",
      "Epoch: 1/1... Training loss: 0.1672\n",
      "Epoch: 1/1... Training loss: 0.0907\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1635\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.0882\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.0687\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1624\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1673\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1579\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1008\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1452\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.0931\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1867\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1048\n",
      "Epoch: 1/1... Training loss: 0.1764\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1782\n",
      "Epoch: 1/1... Training loss: 0.1051\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.0887\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1004\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1682\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.0617\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.0998\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1715\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1153\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1060\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.0943\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1082\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1510\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1626\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.0978\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.0979\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1605\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1611\n",
      "Epoch: 1/1... Training loss: 0.0935\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.0855\n",
      "Epoch: 1/1... Training loss: 0.1067\n",
      "Epoch: 1/1... Training loss: 0.1769\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1662\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.0961\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1276\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1083\n",
      "Epoch: 1/1... Training loss: 0.1060\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1086\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.0712\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1721\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1028\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1019\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.0917\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1512\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1044\n",
      "Epoch: 1/1... Training loss: 0.1760\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1014\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.0630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.0989\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.0924\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1019\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1650\n",
      "Epoch: 1/1... Training loss: 0.1023\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.0904\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1204\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1069\n",
      "Epoch: 1/1... Training loss: 0.1086\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.0897\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1903\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1655\n",
      "Epoch: 1/1... Training loss: 0.1035\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.0947\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.0923\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1068\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1038\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1603\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.0958\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.0958\n",
      "Epoch: 1/1... Training loss: 0.1092\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1098\n",
      "Epoch: 1/1... Training loss: 0.1050\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1120\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1551\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1043\n",
      "Epoch: 1/1... Training loss: 0.0877\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1854\n",
      "Epoch: 1/1... Training loss: 0.0945\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1077\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1022\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1861\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1022\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1689\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1024\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1077\n",
      "Epoch: 1/1... Training loss: 0.1426\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1652\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.0880\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1646\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.0878\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1653\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1067\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1021\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1062\n",
      "Epoch: 1/1... Training loss: 0.1010\n",
      "Epoch: 1/1... Training loss: 0.1067\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.0917\n",
      "Epoch: 1/1... Training loss: 0.0978\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.0953\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1546\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.0978\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1114\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1015\n",
      "Epoch: 1/1... Training loss: 0.1778\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.1063\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.0933\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1092\n",
      "Epoch: 1/1... Training loss: 0.1068\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1086\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1028\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1003\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1968\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1629\n",
      "Epoch: 1/1... Training loss: 0.1031\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.0951\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.0983\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1753\n",
      "Epoch: 1/1... Training loss: 0.0780\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.0999\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.0778\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.0892\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1052\n",
      "Epoch: 1/1... Training loss: 0.1683\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1114\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1044\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1648\n",
      "Epoch: 1/1... Training loss: 0.1596\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1014\n",
      "Epoch: 1/1... Training loss: 0.0898\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1020\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1616\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1680\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.0981\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1737\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.0993\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1845\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1611\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1654\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1286\n",
      "Epoch: 1/1... Training loss: 0.1005\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1153\n",
      "Epoch: 1/1... Training loss: 0.1003\n",
      "Epoch: 1/1... Training loss: 0.1063\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1573\n",
      "Epoch: 1/1... Training loss: 0.0996\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1034\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1718\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.0942\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1050\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1012\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1008\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.0912\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.1652\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.0787\n",
      "Epoch: 1/1... Training loss: 0.1653\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1680\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1277\n",
      "Epoch: 1/1... Training loss: 0.1150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1029\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1717\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.0989\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1561\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1117\n",
      "Epoch: 1/1... Training loss: 0.0936\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1598\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1171\n",
      "Epoch: 1/1... Training loss: 0.1009\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.0922\n",
      "Epoch: 1/1... Training loss: 0.0899\n",
      "Epoch: 1/1... Training loss: 0.1440\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1709\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1650\n",
      "Epoch: 1/1... Training loss: 0.0930\n",
      "Epoch: 1/1... Training loss: 0.1611\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.0989\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1081\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1728\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.0898\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1664\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1039\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1060\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.0842\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.0970\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1643\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1585\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.0849\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.0879\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1054\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1651\n",
      "Epoch: 1/1... Training loss: 0.0909\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1127\n",
      "Epoch: 1/1... Training loss: 0.1109\n",
      "Epoch: 1/1... Training loss: 0.1127\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.0950\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.0974\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.0980\n",
      "Epoch: 1/1... Training loss: 0.0805\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1693\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1673\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1147\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.0986\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1743\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1001\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1054\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.1023\n",
      "Epoch: 1/1... Training loss: 0.1552\n",
      "Epoch: 1/1... Training loss: 0.1290\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.0825\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1518\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1020\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.0979\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.0946\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1618\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1091\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1052\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1519\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1673\n",
      "Epoch: 1/1... Training loss: 0.1519\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.0831\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1615\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1012\n",
      "Epoch: 1/1... Training loss: 0.1144\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.0828\n",
      "Epoch: 1/1... Training loss: 0.1007\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1041\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.0950\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1538\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1045\n",
      "Epoch: 1/1... Training loss: 0.1803\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1729\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1574\n",
      "Epoch: 1/1... Training loss: 0.1806\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.0905\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1236\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1573\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1539\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.0935\n",
      "Epoch: 1/1... Training loss: 0.1828\n",
      "Epoch: 1/1... Training loss: 0.1599\n",
      "Epoch: 1/1... Training loss: 0.0963\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1665\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.0787\n",
      "Epoch: 1/1... Training loss: 0.0862\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.0821\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1208\n",
      "Epoch: 1/1... Training loss: 0.0973\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1437\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1056\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1083\n",
      "Epoch: 1/1... Training loss: 0.1308\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1706\n",
      "Epoch: 1/1... Training loss: 0.1697\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1056\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.0980\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.0889\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1607\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1017\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1179\n",
      "Epoch: 1/1... Training loss: 0.1181\n",
      "Epoch: 1/1... Training loss: 0.1537\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1089\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1756\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1355\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.0863\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1034\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1750\n",
      "Epoch: 1/1... Training loss: 0.1619\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.0944\n",
      "Epoch: 1/1... Training loss: 0.1156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.0896\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1339\n",
      "Epoch: 1/1... Training loss: 0.1558\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.0934\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1530\n",
      "Epoch: 1/1... Training loss: 0.1260\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1415\n",
      "Epoch: 1/1... Training loss: 0.1571\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.0912\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1626\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1063\n",
      "Epoch: 1/1... Training loss: 0.1041\n",
      "Epoch: 1/1... Training loss: 0.0924\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1434\n",
      "Epoch: 1/1... Training loss: 0.1705\n",
      "Epoch: 1/1... Training loss: 0.1717\n",
      "Epoch: 1/1... Training loss: 0.1005\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1631\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1630\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.0743\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.0991\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1030\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1107\n",
      "Epoch: 1/1... Training loss: 0.1215\n",
      "Epoch: 1/1... Training loss: 0.1343\n",
      "Epoch: 1/1... Training loss: 0.1093\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.0894\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1048\n",
      "Epoch: 1/1... Training loss: 0.1642\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1752\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1830\n",
      "Epoch: 1/1... Training loss: 0.1086\n",
      "Epoch: 1/1... Training loss: 0.1069\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1023\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.0949\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1076\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1191\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1203\n",
      "Epoch: 1/1... Training loss: 0.1007\n",
      "Epoch: 1/1... Training loss: 0.1071\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1691\n",
      "Epoch: 1/1... Training loss: 0.1582\n",
      "Epoch: 1/1... Training loss: 0.1048\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1713\n",
      "Epoch: 1/1... Training loss: 0.1703\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.0977\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.0951\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1640\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1127\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1221\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.0806\n",
      "Epoch: 1/1... Training loss: 0.1107\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.0952\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1336\n",
      "Epoch: 1/1... Training loss: 0.1764\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.0936\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1311\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1068\n",
      "Epoch: 1/1... Training loss: 0.1516\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.0983\n",
      "Epoch: 1/1... Training loss: 0.1609\n",
      "Epoch: 1/1... Training loss: 0.1534\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.0932\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1086\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1579\n",
      "Epoch: 1/1... Training loss: 0.0962\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1656\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.0883\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1615\n",
      "Epoch: 1/1... Training loss: 0.0964\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1233\n",
      "Epoch: 1/1... Training loss: 0.1532\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1153\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1017\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1162\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1562\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1608\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1565\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1186\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1597\n",
      "Epoch: 1/1... Training loss: 0.1380\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1120\n",
      "Epoch: 1/1... Training loss: 0.0957\n",
      "Epoch: 1/1... Training loss: 0.1613\n",
      "Epoch: 1/1... Training loss: 0.1352\n",
      "Epoch: 1/1... Training loss: 0.1249\n",
      "Epoch: 1/1... Training loss: 0.0849\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1198\n",
      "Epoch: 1/1... Training loss: 0.1465\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1815\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1021\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1887\n",
      "Epoch: 1/1... Training loss: 0.1371\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.0939\n",
      "Epoch: 1/1... Training loss: 0.1319\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1195\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1301\n",
      "Epoch: 1/1... Training loss: 0.0973\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1654\n",
      "Epoch: 1/1... Training loss: 0.0964\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1342\n",
      "Epoch: 1/1... Training loss: 0.1701\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.0991\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1033\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1241\n",
      "Epoch: 1/1... Training loss: 0.1544\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1328\n",
      "Epoch: 1/1... Training loss: 0.1097\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1667\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1010\n",
      "Epoch: 1/1... Training loss: 0.1333\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1160\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1514\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1006\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1402\n",
      "Epoch: 1/1... Training loss: 0.1647\n",
      "Epoch: 1/1... Training loss: 0.1212\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.0972\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1037\n",
      "Epoch: 1/1... Training loss: 0.1047\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.0892\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1115\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1269\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1369\n",
      "Epoch: 1/1... Training loss: 0.1046\n",
      "Epoch: 1/1... Training loss: 0.0971\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.0914\n",
      "Epoch: 1/1... Training loss: 0.1167\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1264\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1083\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1381\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1029\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1462\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1095\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1310\n",
      "Epoch: 1/1... Training loss: 0.1509\n",
      "Epoch: 1/1... Training loss: 0.1513\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1130\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1757\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1335\n",
      "Epoch: 1/1... Training loss: 0.1575\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1163\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1475\n",
      "Epoch: 1/1... Training loss: 0.1635\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1304\n",
      "Epoch: 1/1... Training loss: 0.1484\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1052\n",
      "Epoch: 1/1... Training loss: 0.1579\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1629\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1170\n",
      "Epoch: 1/1... Training loss: 0.1643\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1265\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1007\n",
      "Epoch: 1/1... Training loss: 0.1188\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.0968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1408\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1590\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1517\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1332\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.0908\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1786\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1089\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1555\n",
      "Epoch: 1/1... Training loss: 0.1622\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1036\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1064\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1764\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.2102\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1059\n",
      "Epoch: 1/1... Training loss: 0.1045\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1470\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1216\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1155\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1026\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.0927\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1615\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1273\n",
      "Epoch: 1/1... Training loss: 0.1053\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1663\n",
      "Epoch: 1/1... Training loss: 0.1010\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1686\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1527\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1398\n",
      "Epoch: 1/1... Training loss: 0.0802\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1845\n",
      "Epoch: 1/1... Training loss: 0.1129\n",
      "Epoch: 1/1... Training loss: 0.1376\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1529\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1012\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.0994\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1165\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1699\n",
      "Epoch: 1/1... Training loss: 0.1042\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1563\n",
      "Epoch: 1/1... Training loss: 0.1021\n",
      "Epoch: 1/1... Training loss: 0.0960\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.0955\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.1033\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1523\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1073\n",
      "Epoch: 1/1... Training loss: 0.1093\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1196\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.1716\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1037\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1118\n",
      "Epoch: 1/1... Training loss: 0.1105\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1685\n",
      "Epoch: 1/1... Training loss: 0.1671\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.0836\n",
      "Epoch: 1/1... Training loss: 0.1583\n",
      "Epoch: 1/1... Training loss: 0.1550\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1081\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1708\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1429\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1719\n",
      "Epoch: 1/1... Training loss: 0.1008\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1642\n",
      "Epoch: 1/1... Training loss: 0.1750\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1508\n",
      "Epoch: 1/1... Training loss: 0.1458\n",
      "Epoch: 1/1... Training loss: 0.1580\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.0986\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1378\n",
      "Epoch: 1/1... Training loss: 0.1515\n",
      "Epoch: 1/1... Training loss: 0.1085\n",
      "Epoch: 1/1... Training loss: 0.1665\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1117\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1034\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1701\n",
      "Epoch: 1/1... Training loss: 0.1234\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1133\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1863\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1183\n",
      "Epoch: 1/1... Training loss: 0.1138\n",
      "Epoch: 1/1... Training loss: 0.0899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1447\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.0998\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1425\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.1397\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1192\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1054\n",
      "Epoch: 1/1... Training loss: 0.1295\n",
      "Epoch: 1/1... Training loss: 0.1681\n",
      "Epoch: 1/1... Training loss: 0.1645\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1829\n",
      "Epoch: 1/1... Training loss: 0.1081\n",
      "Epoch: 1/1... Training loss: 0.1190\n",
      "Epoch: 1/1... Training loss: 0.0991\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1581\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1610\n",
      "Epoch: 1/1... Training loss: 0.1436\n",
      "Epoch: 1/1... Training loss: 0.1048\n",
      "Epoch: 1/1... Training loss: 0.1545\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1637\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1636\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1090\n",
      "Epoch: 1/1... Training loss: 0.0921\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1531\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.0932\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.1173\n",
      "Epoch: 1/1... Training loss: 0.1309\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1464\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1142\n",
      "Epoch: 1/1... Training loss: 0.1460\n",
      "Epoch: 1/1... Training loss: 0.1846\n",
      "Epoch: 1/1... Training loss: 0.1526\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1226\n",
      "Epoch: 1/1... Training loss: 0.0916\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.1024\n",
      "Epoch: 1/1... Training loss: 0.1034\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1116\n",
      "Epoch: 1/1... Training loss: 0.1606\n",
      "Epoch: 1/1... Training loss: 0.1076\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.0966\n",
      "Epoch: 1/1... Training loss: 0.1516\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1694\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1270\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1218\n",
      "Epoch: 1/1... Training loss: 0.1572\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1032\n",
      "Epoch: 1/1... Training loss: 0.1597\n",
      "Epoch: 1/1... Training loss: 0.1488\n",
      "Epoch: 1/1... Training loss: 0.1217\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1070\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1646\n",
      "Epoch: 1/1... Training loss: 0.0938\n",
      "Epoch: 1/1... Training loss: 0.1065\n",
      "Epoch: 1/1... Training loss: 0.1361\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.0996\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1128\n",
      "Epoch: 1/1... Training loss: 0.1274\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1251\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1019\n",
      "Epoch: 1/1... Training loss: 0.1306\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1394\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1602\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1300\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.0988\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1675\n",
      "Epoch: 1/1... Training loss: 0.1828\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1664\n",
      "Epoch: 1/1... Training loss: 0.1548\n",
      "Epoch: 1/1... Training loss: 0.1383\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1148\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1753\n",
      "Epoch: 1/1... Training loss: 0.1519\n",
      "Epoch: 1/1... Training loss: 0.0849\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1220\n",
      "Epoch: 1/1... Training loss: 0.1625\n",
      "Epoch: 1/1... Training loss: 0.1222\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1194\n",
      "Epoch: 1/1... Training loss: 0.1103\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.0940\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.1089\n",
      "Epoch: 1/1... Training loss: 0.1468\n",
      "Epoch: 1/1... Training loss: 0.1604\n",
      "Epoch: 1/1... Training loss: 0.1503\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1146\n",
      "Epoch: 1/1... Training loss: 0.1033\n",
      "Epoch: 1/1... Training loss: 0.1497\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.0945\n",
      "Epoch: 1/1... Training loss: 0.1363\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1161\n",
      "Epoch: 1/1... Training loss: 0.1228\n",
      "Epoch: 1/1... Training loss: 0.1069\n",
      "Epoch: 1/1... Training loss: 0.1275\n",
      "Epoch: 1/1... Training loss: 0.1431\n",
      "Epoch: 1/1... Training loss: 0.1388\n",
      "Epoch: 1/1... Training loss: 0.1420\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1245\n",
      "Epoch: 1/1... Training loss: 0.1757\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1047\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1346\n",
      "Epoch: 1/1... Training loss: 0.0949\n",
      "Epoch: 1/1... Training loss: 0.1258\n",
      "Epoch: 1/1... Training loss: 0.1246\n",
      "Epoch: 1/1... Training loss: 0.1053\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1106\n",
      "Epoch: 1/1... Training loss: 0.0876\n",
      "Epoch: 1/1... Training loss: 0.1455\n",
      "Epoch: 1/1... Training loss: 0.0857\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1461\n",
      "Epoch: 1/1... Training loss: 0.1052\n",
      "Epoch: 1/1... Training loss: 0.1412\n",
      "Epoch: 1/1... Training loss: 0.1564\n",
      "Epoch: 1/1... Training loss: 0.1043\n",
      "Epoch: 1/1... Training loss: 0.1261\n",
      "Epoch: 1/1... Training loss: 0.0922\n",
      "Epoch: 1/1... Training loss: 0.0982\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1166\n",
      "Epoch: 1/1... Training loss: 0.1417\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1095\n",
      "Epoch: 1/1... Training loss: 0.0914\n",
      "Epoch: 1/1... Training loss: 0.1448\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1745\n",
      "Epoch: 1/1... Training loss: 0.1576\n",
      "Epoch: 1/1... Training loss: 0.1059\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1229\n",
      "Epoch: 1/1... Training loss: 0.1393\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1483\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1147\n",
      "Epoch: 1/1... Training loss: 0.1673\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1302\n",
      "Epoch: 1/1... Training loss: 0.1366\n",
      "Epoch: 1/1... Training loss: 0.1272\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.0888\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1259\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1079\n",
      "Epoch: 1/1... Training loss: 0.1610\n",
      "Epoch: 1/1... Training loss: 0.1111\n",
      "Epoch: 1/1... Training loss: 0.0924\n",
      "Epoch: 1/1... Training loss: 0.1927\n",
      "Epoch: 1/1... Training loss: 0.1520\n",
      "Epoch: 1/1... Training loss: 0.1012\n",
      "Epoch: 1/1... Training loss: 0.1038\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1055\n",
      "Epoch: 1/1... Training loss: 0.1294\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.1087\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1132\n",
      "Epoch: 1/1... Training loss: 0.0944\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1670\n",
      "Epoch: 1/1... Training loss: 0.0959\n",
      "Epoch: 1/1... Training loss: 0.1159\n",
      "Epoch: 1/1... Training loss: 0.1350\n",
      "Epoch: 1/1... Training loss: 0.0992\n",
      "Epoch: 1/1... Training loss: 0.1450\n",
      "Epoch: 1/1... Training loss: 0.0996\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1368\n",
      "Epoch: 1/1... Training loss: 0.1131\n",
      "Epoch: 1/1... Training loss: 0.1237\n",
      "Epoch: 1/1... Training loss: 0.1629\n",
      "Epoch: 1/1... Training loss: 0.1360\n",
      "Epoch: 1/1... Training loss: 0.1314\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1285\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1268\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1239\n",
      "Epoch: 1/1... Training loss: 0.1370\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1143\n",
      "Epoch: 1/1... Training loss: 0.0982\n",
      "Epoch: 1/1... Training loss: 0.0923\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.0802\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1211\n",
      "Epoch: 1/1... Training loss: 0.1201\n",
      "Epoch: 1/1... Training loss: 0.1230\n",
      "Epoch: 1/1... Training loss: 0.1135\n",
      "Epoch: 1/1... Training loss: 0.1207\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1649\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1432\n",
      "Epoch: 1/1... Training loss: 0.1061\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1094\n",
      "Epoch: 1/1... Training loss: 0.0968\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1457\n",
      "Epoch: 1/1... Training loss: 0.1180\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.0922\n",
      "Epoch: 1/1... Training loss: 0.1256\n",
      "Epoch: 1/1... Training loss: 0.1244\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1174\n",
      "Epoch: 1/1... Training loss: 0.1593\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1505\n",
      "Epoch: 1/1... Training loss: 0.1347\n",
      "Epoch: 1/1... Training loss: 0.1214\n",
      "Epoch: 1/1... Training loss: 0.1372\n",
      "Epoch: 1/1... Training loss: 0.1507\n",
      "Epoch: 1/1... Training loss: 0.1157\n",
      "Epoch: 1/1... Training loss: 0.1305\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1197\n",
      "Epoch: 1/1... Training loss: 0.1498\n",
      "Epoch: 1/1... Training loss: 0.0979\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1034\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1140\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1250\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1287\n",
      "Epoch: 1/1... Training loss: 0.1248\n",
      "Epoch: 1/1... Training loss: 0.1326\n",
      "Epoch: 1/1... Training loss: 0.1511\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1172\n",
      "Epoch: 1/1... Training loss: 0.1489\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1628\n",
      "Epoch: 1/1... Training loss: 0.1592\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1634\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1340\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1178\n",
      "Epoch: 1/1... Training loss: 0.1206\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1291\n",
      "Epoch: 1/1... Training loss: 0.1329\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1430\n",
      "Epoch: 1/1... Training loss: 0.1176\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1725\n",
      "Epoch: 1/1... Training loss: 0.1485\n",
      "Epoch: 1/1... Training loss: 0.1615\n",
      "Epoch: 1/1... Training loss: 0.1669\n",
      "Epoch: 1/1... Training loss: 0.1316\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.1473\n",
      "Epoch: 1/1... Training loss: 0.1541\n",
      "Epoch: 1/1... Training loss: 0.1156\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.0735\n",
      "Epoch: 1/1... Training loss: 0.0905\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1185\n",
      "Epoch: 1/1... Training loss: 0.1521\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1566\n",
      "Epoch: 1/1... Training loss: 0.0995\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1654\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.1242\n",
      "Epoch: 1/1... Training loss: 0.1731\n",
      "Epoch: 1/1... Training loss: 0.1113\n",
      "Epoch: 1/1... Training loss: 0.1080\n",
      "Epoch: 1/1... Training loss: 0.1108\n",
      "Epoch: 1/1... Training loss: 0.1325\n",
      "Epoch: 1/1... Training loss: 0.1653\n",
      "Epoch: 1/1... Training loss: 0.1379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1074\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1466\n",
      "Epoch: 1/1... Training loss: 0.1209\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1799\n",
      "Epoch: 1/1... Training loss: 0.1413\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1032\n",
      "Epoch: 1/1... Training loss: 0.1141\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.1427\n",
      "Epoch: 1/1... Training loss: 0.1292\n",
      "Epoch: 1/1... Training loss: 0.1480\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1657\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1496\n",
      "Epoch: 1/1... Training loss: 0.0977\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.0967\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1401\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.0990\n",
      "Epoch: 1/1... Training loss: 0.1082\n",
      "Epoch: 1/1... Training loss: 0.1456\n",
      "Epoch: 1/1... Training loss: 0.1410\n",
      "Epoch: 1/1... Training loss: 0.1492\n",
      "Epoch: 1/1... Training loss: 0.1533\n",
      "Epoch: 1/1... Training loss: 0.1570\n",
      "Epoch: 1/1... Training loss: 0.1075\n",
      "Epoch: 1/1... Training loss: 0.0805\n",
      "Epoch: 1/1... Training loss: 0.1661\n",
      "Epoch: 1/1... Training loss: 0.0916\n",
      "Epoch: 1/1... Training loss: 0.1104\n",
      "Epoch: 1/1... Training loss: 0.1189\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1293\n",
      "Epoch: 1/1... Training loss: 0.0984\n",
      "Epoch: 1/1... Training loss: 0.1063\n",
      "Epoch: 1/1... Training loss: 0.1778\n",
      "Epoch: 1/1... Training loss: 0.0795\n",
      "Epoch: 1/1... Training loss: 0.1344\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1296\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1482\n",
      "Epoch: 1/1... Training loss: 0.1158\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.0936\n",
      "Epoch: 1/1... Training loss: 0.1283\n",
      "Epoch: 1/1... Training loss: 0.1486\n",
      "Epoch: 1/1... Training loss: 0.1773\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1463\n",
      "Epoch: 1/1... Training loss: 0.1594\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.0829\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.0944\n",
      "Epoch: 1/1... Training loss: 0.1193\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1387\n",
      "Epoch: 1/1... Training loss: 0.1107\n",
      "Epoch: 1/1... Training loss: 0.1556\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1392\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1451\n",
      "Epoch: 1/1... Training loss: 0.1362\n",
      "Epoch: 1/1... Training loss: 0.1088\n",
      "Epoch: 1/1... Training loss: 0.1389\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1288\n",
      "Epoch: 1/1... Training loss: 0.1337\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.1400\n",
      "Epoch: 1/1... Training loss: 0.1059\n",
      "Epoch: 1/1... Training loss: 0.1213\n",
      "Epoch: 1/1... Training loss: 0.1528\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1414\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1445\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1317\n",
      "Epoch: 1/1... Training loss: 0.1049\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1003\n",
      "Epoch: 1/1... Training loss: 0.1227\n",
      "Epoch: 1/1... Training loss: 0.1338\n",
      "Epoch: 1/1... Training loss: 0.0930\n",
      "Epoch: 1/1... Training loss: 0.1469\n",
      "Epoch: 1/1... Training loss: 0.1315\n",
      "Epoch: 1/1... Training loss: 0.1444\n",
      "Epoch: 1/1... Training loss: 0.1121\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1020\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1056\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1266\n",
      "Epoch: 1/1... Training loss: 0.1423\n",
      "Epoch: 1/1... Training loss: 0.1139\n",
      "Epoch: 1/1... Training loss: 0.1084\n",
      "Epoch: 1/1... Training loss: 0.1399\n",
      "Epoch: 1/1... Training loss: 0.1284\n",
      "Epoch: 1/1... Training loss: 0.1568\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1395\n",
      "Epoch: 1/1... Training loss: 0.1442\n",
      "Epoch: 1/1... Training loss: 0.1297\n",
      "Epoch: 1/1... Training loss: 0.1403\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1494\n",
      "Epoch: 1/1... Training loss: 0.1586\n",
      "Epoch: 1/1... Training loss: 0.1063\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.0928\n",
      "Epoch: 1/1... Training loss: 0.1312\n",
      "Epoch: 1/1... Training loss: 0.1547\n",
      "Epoch: 1/1... Training loss: 0.0940\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1504\n",
      "Epoch: 1/1... Training loss: 0.1278\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1373\n",
      "Epoch: 1/1... Training loss: 0.1253\n",
      "Epoch: 1/1... Training loss: 0.1145\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1349\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1645\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1493\n",
      "Epoch: 1/1... Training loss: 0.1001\n",
      "Epoch: 1/1... Training loss: 0.1490\n",
      "Epoch: 1/1... Training loss: 0.1428\n",
      "Epoch: 1/1... Training loss: 0.1238\n",
      "Epoch: 1/1... Training loss: 0.1390\n",
      "Epoch: 1/1... Training loss: 0.1727\n",
      "Epoch: 1/1... Training loss: 0.1416\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.1449\n",
      "Epoch: 1/1... Training loss: 0.1151\n",
      "Epoch: 1/1... Training loss: 0.1341\n",
      "Epoch: 1/1... Training loss: 0.1168\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1612\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.0959\n",
      "Epoch: 1/1... Training loss: 0.1048\n",
      "Epoch: 1/1... Training loss: 0.1454\n",
      "Epoch: 1/1... Training loss: 0.1184\n",
      "Epoch: 1/1... Training loss: 0.1375\n",
      "Epoch: 1/1... Training loss: 0.1524\n",
      "Epoch: 1/1... Training loss: 0.1382\n",
      "Epoch: 1/1... Training loss: 0.1377\n",
      "Epoch: 1/1... Training loss: 0.1495\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1477\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1243\n",
      "Epoch: 1/1... Training loss: 0.1324\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1522\n",
      "Epoch: 1/1... Training loss: 0.1411\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1102\n",
      "Epoch: 1/1... Training loss: 0.1632\n",
      "Epoch: 1/1... Training loss: 0.1646\n",
      "Epoch: 1/1... Training loss: 0.1353\n",
      "Epoch: 1/1... Training loss: 0.1559\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1175\n",
      "Epoch: 1/1... Training loss: 0.1459\n",
      "Epoch: 1/1... Training loss: 0.1331\n",
      "Epoch: 1/1... Training loss: 0.1225\n",
      "Epoch: 1/1... Training loss: 0.1086\n",
      "Epoch: 1/1... Training loss: 0.1506\n",
      "Epoch: 1/1... Training loss: 0.1478\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.0959\n",
      "Epoch: 1/1... Training loss: 0.1540\n",
      "Epoch: 1/1... Training loss: 0.1438\n",
      "Epoch: 1/1... Training loss: 0.1124\n",
      "Epoch: 1/1... Training loss: 0.1421\n",
      "Epoch: 1/1... Training loss: 0.1154\n",
      "Epoch: 1/1... Training loss: 0.1348\n",
      "Epoch: 1/1... Training loss: 0.1282\n",
      "Epoch: 1/1... Training loss: 0.1231\n",
      "Epoch: 1/1... Training loss: 0.1643\n",
      "Epoch: 1/1... Training loss: 0.1626\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1040\n",
      "Epoch: 1/1... Training loss: 0.0997\n",
      "Epoch: 1/1... Training loss: 0.1472\n",
      "Epoch: 1/1... Training loss: 0.0840\n",
      "Epoch: 1/1... Training loss: 0.1235\n",
      "Epoch: 1/1... Training loss: 0.1577\n",
      "Epoch: 1/1... Training loss: 0.1379\n",
      "Epoch: 1/1... Training loss: 0.1557\n",
      "Epoch: 1/1... Training loss: 0.1357\n",
      "Epoch: 1/1... Training loss: 0.1318\n",
      "Epoch: 1/1... Training loss: 0.1298\n",
      "Epoch: 1/1... Training loss: 0.1672\n",
      "Epoch: 1/1... Training loss: 0.1327\n",
      "Epoch: 1/1... Training loss: 0.1077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Training loss: 0.1567\n",
      "Epoch: 1/1... Training loss: 0.0936\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1642\n",
      "Epoch: 1/1... Training loss: 0.1303\n",
      "Epoch: 1/1... Training loss: 0.1224\n",
      "Epoch: 1/1... Training loss: 0.1578\n",
      "Epoch: 1/1... Training loss: 0.1330\n",
      "Epoch: 1/1... Training loss: 0.1351\n",
      "Epoch: 1/1... Training loss: 0.1137\n",
      "Epoch: 1/1... Training loss: 0.1152\n",
      "Epoch: 1/1... Training loss: 0.1059\n",
      "Epoch: 1/1... Training loss: 0.1798\n",
      "Epoch: 1/1... Training loss: 0.0940\n",
      "Epoch: 1/1... Training loss: 0.0887\n",
      "Epoch: 1/1... Training loss: 0.1177\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1057\n",
      "Epoch: 1/1... Training loss: 0.1313\n",
      "Epoch: 1/1... Training loss: 0.1210\n",
      "Epoch: 1/1... Training loss: 0.1247\n",
      "Epoch: 1/1... Training loss: 0.1356\n",
      "Epoch: 1/1... Training loss: 0.0617\n",
      "Epoch: 1/1... Training loss: 0.1095\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1334\n",
      "Epoch: 1/1... Training loss: 0.1441\n",
      "Epoch: 1/1... Training loss: 0.1066\n",
      "Epoch: 1/1... Training loss: 0.1405\n",
      "Epoch: 1/1... Training loss: 0.0987\n",
      "Epoch: 1/1... Training loss: 0.1126\n",
      "Epoch: 1/1... Training loss: 0.1467\n",
      "Epoch: 1/1... Training loss: 0.1119\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1435\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1549\n",
      "Epoch: 1/1... Training loss: 0.1386\n",
      "Epoch: 1/1... Training loss: 0.1474\n",
      "Epoch: 1/1... Training loss: 0.1409\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1491\n",
      "Epoch: 1/1... Training loss: 0.1365\n",
      "Epoch: 1/1... Training loss: 0.1279\n",
      "Epoch: 1/1... Training loss: 0.1471\n",
      "Epoch: 1/1... Training loss: 0.1072\n",
      "Epoch: 1/1... Training loss: 0.1479\n",
      "Epoch: 1/1... Training loss: 0.1240\n",
      "Epoch: 1/1... Training loss: 0.1149\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1320\n",
      "Epoch: 1/1... Training loss: 0.1199\n",
      "Epoch: 1/1... Training loss: 0.1078\n",
      "Epoch: 1/1... Training loss: 0.1110\n",
      "Epoch: 1/1... Training loss: 0.0946\n",
      "Epoch: 1/1... Training loss: 0.1772\n",
      "Epoch: 1/1... Training loss: 0.1561\n",
      "Epoch: 1/1... Training loss: 0.1658\n",
      "Epoch: 1/1... Training loss: 0.1182\n",
      "Epoch: 1/1... Training loss: 0.1307\n",
      "Epoch: 1/1... Training loss: 0.1153\n",
      "Epoch: 1/1... Training loss: 0.1499\n",
      "Epoch: 1/1... Training loss: 0.1407\n",
      "Epoch: 1/1... Training loss: 0.1358\n",
      "Epoch: 1/1... Training loss: 0.1422\n",
      "Epoch: 1/1... Training loss: 0.1535\n",
      "Epoch: 1/1... Training loss: 0.1983\n",
      "Epoch: 1/1... Training loss: 0.1028\n",
      "Epoch: 1/1... Training loss: 0.1396\n",
      "Epoch: 1/1... Training loss: 0.1164\n",
      "Epoch: 1/1... Training loss: 0.1099\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1443\n",
      "Epoch: 1/1... Training loss: 0.0814\n",
      "Epoch: 1/1... Training loss: 0.1406\n",
      "Epoch: 1/1... Training loss: 0.1006\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1367\n",
      "Epoch: 1/1... Training loss: 0.1008\n",
      "Epoch: 1/1... Training loss: 0.1023\n",
      "Epoch: 1/1... Training loss: 0.1453\n",
      "Epoch: 1/1... Training loss: 0.1424\n",
      "Epoch: 1/1... Training loss: 0.1125\n",
      "Epoch: 1/1... Training loss: 0.1543\n",
      "Epoch: 1/1... Training loss: 0.1281\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1364\n",
      "Epoch: 1/1... Training loss: 0.1404\n",
      "Epoch: 1/1... Training loss: 0.1359\n",
      "Epoch: 1/1... Training loss: 0.1668\n",
      "Epoch: 1/1... Training loss: 0.0887\n",
      "Epoch: 1/1... Training loss: 0.1623\n",
      "Epoch: 1/1... Training loss: 0.0929\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1299\n",
      "Epoch: 1/1... Training loss: 0.1289\n",
      "Epoch: 1/1... Training loss: 0.1262\n",
      "Epoch: 1/1... Training loss: 0.1267\n",
      "Epoch: 1/1... Training loss: 0.1073\n",
      "Epoch: 1/1... Training loss: 0.1058\n",
      "Epoch: 1/1... Training loss: 0.1205\n",
      "Epoch: 1/1... Training loss: 0.1536\n",
      "Epoch: 1/1... Training loss: 0.1127\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1418\n",
      "Epoch: 1/1... Training loss: 0.1134\n",
      "Epoch: 1/1... Training loss: 0.1385\n",
      "Epoch: 1/1... Training loss: 0.1384\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1600\n",
      "Epoch: 1/1... Training loss: 0.1446\n",
      "Epoch: 1/1... Training loss: 0.1502\n",
      "Epoch: 1/1... Training loss: 0.1123\n",
      "Epoch: 1/1... Training loss: 0.1200\n",
      "Epoch: 1/1... Training loss: 0.1252\n",
      "Epoch: 1/1... Training loss: 0.1476\n",
      "Epoch: 1/1... Training loss: 0.1682\n",
      "Epoch: 1/1... Training loss: 0.1679\n",
      "Epoch: 1/1... Training loss: 0.1039\n",
      "Epoch: 1/1... Training loss: 0.1071\n",
      "Epoch: 1/1... Training loss: 0.1322\n",
      "Epoch: 1/1... Training loss: 0.0971\n",
      "Epoch: 1/1... Training loss: 0.1024\n",
      "Epoch: 1/1... Training loss: 0.1202\n",
      "Epoch: 1/1... Training loss: 0.1255\n",
      "Epoch: 1/1... Training loss: 0.1219\n",
      "Epoch: 1/1... Training loss: 0.1067\n",
      "Epoch: 1/1... Training loss: 0.1187\n",
      "Epoch: 1/1... Training loss: 0.1542\n",
      "Epoch: 1/1... Training loss: 0.1560\n",
      "Epoch: 1/1... Training loss: 0.1257\n",
      "Epoch: 1/1... Training loss: 0.1747\n",
      "Epoch: 1/1... Training loss: 0.1354\n",
      "Epoch: 1/1... Training loss: 0.1323\n",
      "Epoch: 1/1... Training loss: 0.1501\n",
      "Epoch: 1/1... Training loss: 0.1271\n",
      "Epoch: 1/1... Training loss: 0.1419\n",
      "Epoch: 1/1... Training loss: 0.1617\n",
      "Epoch: 1/1... Training loss: 0.1169\n",
      "Epoch: 1/1... Training loss: 0.1345\n",
      "Epoch: 1/1... Training loss: 0.1122\n",
      "Epoch: 1/1... Training loss: 0.1263\n",
      "Epoch: 1/1... Training loss: 0.1072\n",
      "Epoch: 1/1... Training loss: 0.1554\n",
      "Epoch: 1/1... Training loss: 0.1254\n",
      "Epoch: 1/1... Training loss: 0.1525\n",
      "Epoch: 1/1... Training loss: 0.1439\n",
      "Epoch: 1/1... Training loss: 0.1015\n",
      "Epoch: 1/1... Training loss: 0.1391\n",
      "Epoch: 1/1... Training loss: 0.1487\n",
      "Epoch: 1/1... Training loss: 0.1374\n",
      "Epoch: 1/1... Training loss: 0.1136\n",
      "Epoch: 1/1... Training loss: 0.1614\n",
      "Epoch: 1/1... Training loss: 0.1280\n",
      "Epoch: 1/1... Training loss: 0.1500\n",
      "Epoch: 1/1... Training loss: 0.1321\n",
      "Epoch: 1/1... Training loss: 0.0970\n",
      "Epoch: 1/1... Training loss: 0.1433\n",
      "Epoch: 1/1... Training loss: 0.0835\n",
      "Epoch: 1/1... Training loss: 0.1051\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "epochs = 1\n",
    "batch_size = 5\n",
    "# Set's how much noise we're adding to the MNIST images\n",
    "noise_factor = 0.7 # noise factor is in between 0 and 1. 0 is less and 1 is high\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Parameters for determining dynamic learning rate\n",
    "max_learning_rate = 0.001\n",
    "min_learning_rate = 0.0001\n",
    "decay_speed = 2000.0\n",
    "\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    for ii in range(data.train.num_examples//batch_size): # Rounded division\n",
    "        lr= min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-ii/decay_speed)\n",
    "        \n",
    "        batch = data.train.next_batch(batch_size)\n",
    "        # Get images from the batch\n",
    "        imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        \n",
    "        # Add random noise to the input images\n",
    "        noisy_imgs = imgs + noise_factor * np.random.randn(*imgs.shape)\n",
    "        # Clip the images to be between 0 and 1\n",
    "        noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "        \n",
    "        # Noisy images as inputs, original images as targets\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={input_image: noisy_imgs,targets_: imgs,learning_rate:lr})\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Test method:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_model(batch_size):\n",
    "    n=batch_size\n",
    "    canvas_orig = np.empty((28 * n, 28 * n))\n",
    "    canvas_noisy = np.empty((28 * n, 28 * n))\n",
    "    canvas_recon = np.empty((28 * n, 28 * n))\n",
    "    for i in range(n):\n",
    "        # MNIST test set\n",
    "        batch,_  = data.test.next_batch(n)\n",
    "    \n",
    "        imgs = batch.reshape((-1, 28, 28, 1)) #original batch of test image\n",
    "        #noisy_imgs = imgs + noise_factor * np.random.randn(*imgs.shape)\n",
    "        noisy_imgs = imgs + 0.5 * np.random.randn(*imgs.shape)\n",
    "        # Clip the pixel values of the image in between 0.0 and 1.0\n",
    "        noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "        \n",
    "        # Reconstruct the noisy image through the trined model(Encode and decode)\n",
    "        FIm=sess.run(Reconstructed_Image,feed_dict={input_image: noisy_imgs})\n",
    "\n",
    "        # Display original images\n",
    "        for j in range(n):\n",
    "            # Draw the original digit images\n",
    "            canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = batch[j].reshape([28, 28])\n",
    "        #Display noisy image\n",
    "        for j in range(n):\n",
    "            # Draw the noisy digit images\n",
    "            canvas_noisy[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = noisy_imgs[j].reshape([28, 28])\n",
    "        # Display reconstructed images\n",
    "        for j in range(n):\n",
    "            # Draw the reconstructed digit images\n",
    "            canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = FIm[j].reshape([28, 28])\n",
    "\n",
    "    print(\"Original Images\")\n",
    "    plt.figure(figsize=(n, n))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(canvas_orig, origin=\"upper\", cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Noisy Images with noise factor of 0.5 as input\")\n",
    "    plt.figure(figsize=(n, n))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(canvas_noisy, origin=\"upper\", cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Reconstructed Images from the noisy images\")\n",
    "    plt.figure(figsize=(n, n))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(canvas_recon, origin=\"upper\", cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do the Test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Images\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAEyCAYAAACF03cPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhhEIbLMzDCMQ2GZnGEYgsM3OMIxA8P/bPBar3AZzHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121b22fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy Images with noise factor of 0.5 as input\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAEyCAYAAACF03cPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwZg0VQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121b3ddd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed Images from the noisy images\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAEyCAYAAACF03cPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121e14710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Test_model(batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "tensorflow3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nteract": {
   "version": "0.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
